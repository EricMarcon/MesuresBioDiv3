[{"path":"index.html","id":"motivation","chapter":"Motivation","heading":"Motivation","text":"Le terme biodiversity est attribué (Meine, Soulé, Noss 2006) à Walter Rosen, un membre du National Research Council américain, qui commencé à contracter les termes biological diversity pendant la préparation d’un colloque dont les actes seront publiés sous le titre “Biodiversity” (E. O. Wilson Peter 1988).\nLa question de la diversité biologique intéressait les écologues bien avant l’invention de la biodiversité, mais le néologisme connu un succès fulgurant (Blandin 2014) en même temps qu’il devenait une notion floue, dans lequel chacun peut placer ce qu’il souhaite y trouver, au point de lui retirer son caractère scientifique (Delord 2014).\nUne cause de ce glissement est que la biodiversité été nommée pour attirer l’attention sur son érosion, en lien avec la biologie de la conservation.\nCette érosion concernant potentiellement de nombreux aspects du monde vivant, la définition de la biodiversité fluctue selon les besoins : DeLong (1996) en recense 85 dans les dix premières années de littérature.\nLes indicateurs de la biodiversité peuvent englober bien d’autres choses que la diversité du vivant : le nombre d’espèces menacées (par exemple la liste rouge de l’IUCN), la taille des populations ou la surface des écosystèmes préservés, la dégradation des habitats, la menace pesant sur des espèces emblématiques…\nUne mesure rigoureuse et cohérente de la diversité peut pourtant être construite pour clarifier beaucoup (mais pas tous) des concepts qui constituent la biodiversité.Dans l’introduction du premier chapitre des actes de ce qui était devenu le “Forum sur la Biodiversité”, Wilson utilise le mot dans le sens étroit de nombres d’espèces.\nL’élargissement de la notion aux “systèmes naturels” et à l’opposé à la diversité génétique intraspécifique est venu du monde de la conservation (Speth, Holdgate, Tolba 1992).\nLa déclaration de Michel Loreau, président du du comité scientifique de la conférence de Paris en 2005 (Loreau 2005) en donne une définition aboutie :La Terre abrite une extraordinaire diversité biologique, qui inclut non seulement les espèces qui habitent notre planète, mais aussi la diversité de leurs gènes, la multitude des interactions écologiques entre elles et avec leur environnement physique, et la variété des écosystèmes complexes qu’elles constituent.\nCette biodiversité, qui est le produit de plus de 3 milliards d’années d’évolution, constitue un patrimoine naturel et une ressource vitale dont l’humanité dépend de multiples façons.Aujourd’hui encore, le terme biodiversité concerne le plus souvent la richesse en espèces d’un écosystème.\nPour simplifier la présentation, le niveau d’étude dans ce document sera en général celui des espèces (autre concept flou, Hey 2001).\nLa prise en compte de la totalité des êtres vivants est généralement hors de portée.\nLa mesure de diversité est alors limitée à un taxocène, c’est-à-dire un sous-ensemble des espèces d’une communauté reliées taxonomiquement : les papillons, les mammifères, les arbres (la délimitation du sous-ensemble n’est pas forcément strictement taxonomique)…Un objet privilégié des études sur la biodiversité est, depuis le Forum, la forêt tropicale parce qu’elle est très diverse et un enjeu pour la conservation.\nLa plupart des exemples concerneront ici les arbres de la forêt tropicale, qui ont l’avantage d’être clairement définis en tant qu’individus (donc simples à compter) et posent des problèmes méthodologiques considérables pour l’estimation de leur diversité à partir de données réelles.peut bien évidemment s’intéresser à d’autres niveaux et d’autres objets, par exemple la diversité génétique (en termes d’allèles différents pour certains gènes ou marqueurs) à l’intérieur d’une population, ou même la diversité des interactions entre espèces d’une communauté (Jizhong, Shijun, Changming 1991).\ngardera toujours à l’esprit que la prise en compte de la diversité spécifique n’est pas la seule approche, les méthodes présentées ici s’appliquent à la mesure de la diversité en général, pas même nécessairement biologique.L’objectif de ce document est de traiter la mesure de la biodiversité, pas son importance en tant que telle.\nse référera par exemple à Chapin et al. (2000) pour une revue sur cette question, Cardinale et al. (2012) pour les conséquences de l’érosion de la biodiversité sur les services écosystémiques ou Ceballos, Ehrlich, Dirzo (2017) pour les propriétés autocatalytiques de la biodiversité.La mesure de la diversité est un sujet important en tant que tel (Purvis Hector 2000), pour permettre de formaliser les concepts et de les appliquer à la réalité.\nLa question est loin d’être épuisée, et fait toujours l’objet d’une recherche active et de controverses (Ricotta 2005b).","code":""},{"path":"calculs-et-données.html","id":"calculs-et-données","chapter":"Calculs et données","heading":"Calculs et données","text":"La présentation des mesures de diversité est donnée avec un usage intensif du formalisme mathématique.\nLa liste des notations est fournie ci-dessous, s’y référera autant que nécessaire.Les calculs sont réalisés dans R (R Core Team 2023), essentiellement avec le package divent (R-divent?), qui succède au package entropart (Marcon Hérault 2015).\nL’ensemble du code est disponible sur GitHub1 où se trouvent les mises à jour de ce document2.Les données sont souvent celles de la parcelle 6 de la forêt de Paracou (figure 0.1 en Guyane française (Gourlet-Fleury, Guehl, Laroussinie 2004), d’une surface de 6.25 ha.\nTous les arbres de plus de 10 cm de diamètre à hauteur de poitrine (DBH : Diameter Breast Height) y ont été inventoriés en 2016.\nLa position de chaque arbre, son espèce et sa surface terrière sont fournis.D’autres exemples utilisent la parcelle forestière permanente de Barro Colorado Island, souvent abrégée BCI (Condit, Chisholm, Hubbell 2012) : 50 ha de forêt tropicale dont les arbres de plus de 1 cm de diamètre à hauteur de poitrine (DBH : Diameter Breast Height) ont été inventoriés.\nLe jeu de données utilisé pour les exemples est une version réduite aux arbres de plus de 10 cm disponible dans le package vegan (Oksanen et al. 2012), soient 21457 arbres dans 225 espèces.\nFigure 0.1: Carte de la parcelle 6 de Paracou. Les points représentent les arbres. Leur taille est proportionnelle à leur surface terrière. Seules les espèces les plus fréquentes sont identifiées sur la carte.\nLe code R pour réaliser la figure est le suivant :","code":"\nlibrary(\"divent\")\nparacou_6_wmppp %>% \nautoplot(\n  labelSize = expression(paste(\"Surface terrière (\", cm^2, \")\")), \n  labelColor = \"Espèce\"\n) +\ntheme(legend.position = \"bottom\", legend.direction = \"vertical\", legend.margin=margin())"},{"path":"notations.html","id":"notations","chapter":"Notations","heading":"Notations","text":"Les notations mathématiques peuvent différer de celles de la littérature citée pour l’homogénéité de ce document.Les matrices sont notées en caractères gras et majuscules : \\(\\mathbf{X}\\).\nLes éléments de la matrice \\(\\mathbf{X}\\) sont notés \\(x_{,j}\\).Les vecteurs sont notés en gras minuscule : \\(\\mathbf{p}\\).\nLes nombres sont notés en minuscules, \\(n\\), et les variables aléatoires en majuscules : \\(N\\).\nLes valeurs maximales des énumérations font exception : elles sont notées en majuscules pour les distinguer des indices : \\(\\sum_{s=1}^{S}{p_s}=1\\).Le produit matriciel de \\(\\mathbf{X}\\) et \\(\\mathbf{Y}\\) est noté \\(\\mathbf{X}\\mathbf{Y}\\). Dans les scripts R, l’opérateur est %*%.\nLe produit de Hadamard (terme à terme) est noté \\(\\mathbf{X}\\circ\\mathbf{Y}\\) (opérateur * dans R).\nDe même \\(\\mathbf{X}^n\\) indique la puissance \\(n\\) au sens du produit matriciel d’une matrice carrée (opérateur %^% du package expm), alors que \\(\\mathbf{X}^{\\circ n}\\) est la matrice dont chaque terme est celui de \\(\\mathbf{X}\\) à la puissance \\(n\\) (opérateur ^ de R).\nLa matrice transposée de \\(\\mathbf{X}\\) est notée \\(\\mathbf{X'}\\).Les notations sont les suivantes :\\({\\mathbf 1}(\\cdot)\\): la fonction indicatrice, qui vaut 1 si la condition dans la parenthèse est vraie, 0 sinon.\\(\\mathbf{1}_s\\): le vecteur de longueur \\(s\\) composé uniquement de 1. \\(\\mathbf{1}_s\\mathbf{1}_s'=\\mathbf{J}_s\\) où \\(\\mathbf{J}_s\\) est la matrice carré de taille \\(s\\) ne contenant que des 1.\\(\\): l’aire d’étude, et, selon le contexte, sa surface.\\(C\\): le taux de couverture de l’échantillon, c’est-à-dire la probabilité qu’un individu de la communauté appartienne à une des espèces échantillonnées.\n\\(C^{n}\\) est le taux de couverture correspondant à un échantillon de taille \\(n\\).\\(^{q}\\!D\\): la diversité vraie (nombre de Hill pour les diversités \\(\\alpha\\) et \\(\\gamma\\)), nombre équivalent de communautés pour la diversité \\(\\beta\\).\n\\(^{q}_{}\\!D_{\\alpha}\\) est la diversité \\(\\alpha\\) mesurée dans la communauté \\(\\).\n\\(^{q}\\!\\bar{D}\\left(T\\right)\\) est la diversité phylogénétique.\\(\\boldsymbol{\\Delta}\\): la matrice de dissimilarité dont les éléments sont \\(\\delta_{s,t}\\), la dissimilarité entre l’espèce \\(s\\) et l’espèce \\(t\\).\\({\\mathbb E}\\left(X\\right)\\): l’espérance de la variable aléatoire \\(X\\).\\(f_{\\nu}\\): le nombre d’espèces observées \\(\\nu\\) fois dans un échantillon (qui peut être défini par sa surface ou son nombre d’individus).\n\\(f_{>0}\\) est le nombre d’espèces observées au moins une fois.\n\\(f_1\\) s’appelle le nombre de singletons et \\(f_2\\) le nombre de doubletons.\\(^{q}\\!H\\): l’entropie de Tsallis (ou HCDT).\n\\(^{q}_{}\\!H_{\\alpha}\\) est l’entropie \\(\\alpha\\) mesurée dans la communauté \\(\\).\nSi nécessaire, le vecteur des probabilités servant au calcul est précisé sous la forme \\(^{q}\\!H(\\mathbf{p})\\).\n\\(^{q}\\!\\bar{H}(T)\\) est l’entropie phylogénétique.\\(\\): le nombre de communautés qui constituent une partition de la méta-communauté dans le cadre de la décomposition de la diversité.\nLes communautés sont indexées par \\(\\).\\((p_s)\\): l’information apportée par l’observation d’un évènement de probabilité \\(p_s\\).\n\\((q_s,p_s)\\) est le gain d’information apporté par l’expérience (\\(q_s\\) est observé) par rapport aux probabilités \\(p_s\\) attendues.\\(\\mathbf{}_s\\): la matrice identité de rang \\(s\\): matrice carrée de taille \\(s\\times s\\) dont la diagonale ne comporte que des 1 et les autres éléments sont nuls.\\(N\\): le nombre (aléatoire) d’individus se trouvant dans l’aire d’étude.\n\\(N_s\\) est la même variable aléatoire, mais restreinte aux individus de l’espèce \\(s\\).\\(n\\): le nombre d’individus échantillonnés.\n\\(n_{s,}\\) est le nombre d’individus de l’espèce \\(s\\) dans la communauté \\(\\).\nLes effectifs totaux sont \\(n_{s+}\\) (pour l’espèce \\(s\\)), \\(n_{+}\\) pour la communauté \\(\\) et \\(n\\) le total général.\nS’il n’y qu’une communauté, le nombre d’individus par espèce est \\(n_s\\).\\(p_s\\): la probabilité qu’un individu tiré au hasard appartienne à l’espèce \\(s\\), autrement dit la probabilité de l’espèce \\(s\\).\nSon estimateur le plus simple, \\({\\hat{p}}_s\\) est la fréquence observée.\nSelon le contexte, \\({\\hat{p}}_s\\) peut désigner un estimateur plus élaboré.\n\\(p_{s|}\\) est la même probabilité dans la communauté \\(\\).\n\\(p_{\\nu}\\) est la probabilité d’une espèce observées \\(\\nu\\) fois dans un échantillon.\\(\\mathbf{p}=\\left( p_1, p_2, \\dots, p_s, \\dots, p_S \\right)\\): le vecteur décrivant la distribution des probabilités \\(p_s\\), appelé simplexe en référence à sa représentation dans l’espace à \\(S\\) dimensions.\\({\\pi}_{\\nu}\\): la probabilité qu’une espèce choisie au hasard soit représentée par \\(\\nu\\) individus, \\(\\sum^n_{\\nu=1}{{\\pi}_{\\nu}}\\)=1.\nSi l’espèce est choisie explicitement, la probabilité est notée \\({\\pi}_{n_s}\\).\\(^{q}\\!R\\): l’entropie de Rényi d’ordre \\(q\\).\\(S\\): le nombre d’espèces d’une communauté, considéré comme une variable aléatoire, estimé par \\(\\hat{S}\\).\\(S()\\) et \\(S(n)\\): le nombre d’espèces, considéré comme une fonction de la taille de l’échantillon.\\(t^{n}_{1-\\alpha/2}\\): le quantile d’une loi de Student à \\(n\\) degrés de liberté au seuil de risque \\(\\alpha\\), classiquement 1,96 pour \\(n\\) grand et \\(\\alpha=5\\%\\).\\(\\mathbf{Z}\\): la matrice de similarité entre espèces dont les éléments sont \\(z_{s,t}\\), la similarité entre l’espèce \\(s\\) et l’espèce \\(t\\).\\(\\mathrm{\\Gamma}(\\cdot)\\): la fonction gamma.\\(\\mathrm{\\Psi}(\\cdot)\\): la fonction digamma.\\(\\binom{n}{k}\\): le nombre de combinaisons de \\(k\\) éléments parmi \\(n\\): \\[\\binom{n}{k}=\\frac{n!}{k!\\,(n-k)!}\\].","code":""},{"path":"chap-Notions.html","id":"chap-Notions","chapter":"1 Notions de Diversité","heading":"1 Notions de Diversité","text":"","code":""},{"path":"chap-Notions.html","id":"composantes","chapter":"1 Notions de Diversité","heading":"1.1 Composantes","text":"\nFigure 1.1: Importance de la richesse (en haut) et de l’équitabilité (en bas) pour la définition de la diversité. Ligne du haut : toutes choses égales par ailleurs, une communauté de 7 espèces semble plus diverse qu’une communauté de 2 espèces. Ligne du bas : à richesse égale, une communauté moins équitable (à gauche) semble moins diverse. Colonne de gauche : une communauté moins riche (en haut) peut sembler plus diverse si elle est plus équitable. Colonne de droite : idem pour la communauté du bas.\nUne communauté comprenant beaucoup d’espèces mais avec une espèce dominante n’est pas perçue intuitivement comme plus diverse qu’une communauté avec moins d’espèces, mais dont les effectifs sont proches (figure 1.1, colonne de gauche).\nLa prise en compte de deux composantes de la diversité, appelées richesse et équitabilité, est nécessaire (Whittaker 1965).","code":""},{"path":"chap-Notions.html","id":"richesse","chapter":"1 Notions de Diversité","heading":"1.1.1 Richesse","text":"La richesse (terme introduit par Mcintosh 1967) est le nombre (ou une fonction croissante du nombre) de classes différentes présentes dans le système étudié, par exemple le nombre d’espèces d’arbres dans une forêt.Un certain nombre d’hypothèses sont assumées plus ou moins explicitement :Les classes sont bien connues : compter le nombre d’espèces peu de sens si la taxonomie n’est pas bien établie.\nC’est parfois une difficulté majeure quand travaille sur les micro-organismes ;Les classes sont équidistantes : la richesse augmente d’une unité quand rajoute une espèce, que cette espèce soit proche des précédentes ou extrêmement originale.L’indice de richesse le plus simple et le plus utilisé est tout simplement le nombre d’espèces \\(S\\).","code":""},{"path":"chap-Notions.html","id":"équitabilité","chapter":"1 Notions de Diversité","heading":"1.1.2 Équitabilité","text":"La régularité de la distribution des espèces (équitabilité en Français, evenness ou equitability en anglais) est un élément important de la diversité.\nUne espèce représentée abondamment ou par un seul individu n’apporte pas la même contribution à l’écosystème.\nSur la figure 1.1, la ligne du bas présente deux communautés de 4 espèces, mais celle de droite est beaucoup plus équitable de celle de gauche et semble intuitivement plus diverse.\nÀ nombre d’espèces égal, la présence d’espèces très dominantes entraîne mathématiquement la rareté de certaines autres : comprend donc assez intuitivement que le maximum de diversité sera atteint quand les espèces auront une répartition très régulière.Un indice d’équitabilité est indépendant du nombre d’espèces (donc de la richesse).La plupart des mesures de diversité courantes, comme celle de Simpson ou de Shannon, évaluent à la fois la richesse et l’équitabilité.","code":""},{"path":"chap-Notions.html","id":"disparité","chapter":"1 Notions de Diversité","heading":"1.1.3 Disparité","text":"Les mesures classiques de la diversité, dites mesures de diversité neutre (species-neutral diversity) ou taxonomique ne prennent pas en compte une quelconque distance entre classes.\nPourtant, deux espèces du même genre sont de toute évidence plus proches que deux espèces de familles différentes.\nLes mesures de diversité non neutres (chapitre ??) prennent en compte cette notion, qui nécessite quelques définitions supplémentaires (Mouillot et al. 2005; Ricotta 2007).La mesure de la différence entre deux classes est souvent une distance, mais parfois une mesure qui n’pas toutes les propriétés d’une distance : une dissimilarité.\nLes mesures de divergence (Pavoine Bonsall 2011) sont construites à partir de la dissimilarité entre les classes, avec ou sans pondération par la fréquence.Si la divergence entre espèces est une distance évolutive comme l’âge du plus récent ancêtre commun, la diversité sera dite phylogénétique.\nSi c’est une distance fonctionnelle, définie par exemple dans l’espace des traits fonctionnels, la diversité sera dite fonctionnelle.La disparité (Runnegar 1987), divergence moyenne entre deux espèces (indépendamment des fréquences), ou de façon équivalente la longueur totale des branches d’un arbre phylogénétique, est la composante qui décrit à quel point les espèces sont différentes les unes des autres.Les mesures de régularité décrivent la façon dont les espèces occupent l’espace des niches (régularité fonctionnelle) ou la régularité dans le temps et entre les clades des évènements de spéciation représentés par un arbre phylogénétique.\nCe concept complète celui d’équitabilité dans les mesures classiques : la diversité augmente avec la richesse, la divergence entre espèces, et la régularité (qui se réduit à l’équitabilité quand toutes les espèces sont également divergentes entre elles).","code":""},{"path":"chap-Notions.html","id":"agrégation","chapter":"1 Notions de Diversité","heading":"1.1.4 Agrégation","text":"À partir d’une large revue de la littérature dans plusieurs disciplines scientifiques s’intéressant à la diversité (au-delà de la biodiversité), Stirling (2007) estime que les trois composantes, qu’il nomme variété (richesse), équilibre (équitabilité) et disparité, recouvrent tous les aspects de la diversité.Stirling définit la propriété d’agrégation comme la capacité d’une mesure de diversité à combiner explicitement les trois composantes précédentes.\nCela ne signifie pas que les composantes contribuent indépendamment les unes des autres à la diversité (Jost 2010).","code":""},{"path":"chap-Notions.html","id":"niveaux-de-létude","chapter":"1 Notions de Diversité","heading":"1.2 Niveaux de l’étude","text":"La diversité est classiquement estimée à plusieurs niveaux emboîtés, nommés \\(\\alpha\\), \\(\\beta\\) et \\(\\gamma\\) par Whittaker (1960, 320) qui nommé \\(\\alpha\\) la diversité locale qu’il mesurait avec l’indice \\(\\alpha\\) de Fisher (voir le chapitre ??) et utilisé les lettres suivantes selon ses besoins.","code":""},{"path":"chap-Notions.html","id":"diversité-alpha-beta-et-gamma","chapter":"1 Notions de Diversité","heading":"1.2.1 Diversité \\(\\alpha\\), \\(\\beta\\) et \\(\\gamma\\)","text":"La diversité \\(\\alpha\\) est la diversité locale, mesurée à l’intérieur d’un système délimité.\nPlus précisément, il s’agit de la diversité dans un habitat uniforme de taille fixe.\nFigure 1.2: Patrons de biodiversité. () Le nombre d’espèces de vers de terre augmente en fonction de la surface échantillonnée, de 100 m² à plus de 500000 km² selon la relation d’Arrhenius). (b) Nombre d’espèces d’oiseaux en fonction de la latitude. (c) Relation entre la richesse régionale et la richesse locale. (d) Nombre d’espèces de chauves-souris en fonction de l’altitude dans une réserve au Pérou. (e) Nombre d’espèces de végétaux ligneux en fonction des précipitations en Afrique du Sud.\nDe façon générale (Gaston 2000), la richesse spécifique diminue avec la latitude (la diversité est plus grande dans les zones tropicales, et au sein de celles-ci, quand se rapproche de l’équateur), voir figure 1.2 (Gaston 2000, fig. 1).\nLa tendance est la même pour la diversité génétique intraspécifique (Miraldo et al. 2016).\nLa richesse diminue avec l’altitude.\nElle est généralement plus faible sur les îles, où elle décroît avec la distance au continent, source de migrations.La diversité \\(\\beta\\) mesure à quel point les systèmes locaux sont différents.\nCette définition assez vague fait l’objet de nombreux débats (Moreno Rodríguez 2010).Enfin, la diversité \\(\\gamma\\) est similaire à la diversité \\(\\alpha\\), prise en compte sur l’ensemble du système étudié.\nLes diversités \\(\\alpha\\) et \\(\\gamma\\) se mesurent donc de la même façon, mais à différentes échelles.","code":""},{"path":"chap-Notions.html","id":"décomposition","chapter":"1 Notions de Diversité","heading":"1.2.2 Décomposition","text":"Whittaker (1977) proposé sans succès une normalisation des échelles d’évaluation de la biodiversité, en introduisant la diversité régionale \\(\\varepsilon\\) (\\(\\gamma\\) étant réservé au paysage et \\(\\alpha\\) à l’habitat) et la diversité \\(\\delta\\) entre les paysages.\nSeuls les trois niveaux originaux ont été conservés par la littérature, sans définition stricte des échelles d’observation.La distinction entre les diversités \\(\\alpha\\) et \\(\\beta\\) dépend de la finesse de la définition de l’habitat.\nLa distinction de nombreux habitats diminue la diversité \\(\\alpha\\) au profit de la \\(\\beta\\).\nIl est donc important de définir une mesure qui ne dépende pas de ce découpage, donc une mesure cumulative (additive ou multiplicative) décrivant la diversité totale, décomposable en la somme ou le produit convenablement pondérés de toutes les diversités \\(\\alpha\\) des habitats (diversité intra) et de la diversité \\(\\beta\\) inter-habitat.Nous appellerons communauté le niveau de découpage concernant la diversité \\(\\alpha\\) et méta-communauté le niveau de regroupement pour l’estimation de la diversité \\(\\gamma\\).","code":""},{"path":"chap-Notions.html","id":"courbes-daccumulation","chapter":"1 Notions de Diversité","heading":"1.3 Courbes d’accumulation","text":"\nFigure 1.3: Courbe d’accumulation des espèces d’arbres du dispositif de Barro Colorado Island. Le nombre d’espèces est cumulé dans l’ordre des carrés d’un hectare du dispositif.\nEvaluer la diversité d’une communauté nécessite en pratique de l’inventorier.\nLe nombre d’espèces découvertes en fonction de l’effort d’échantillonnage permet de tracer une courbe d’accumulation (SAC : Species Acumulation Curve).\nUne courbe de raréfaction (Rarefaction Curve) peut être calculée en réduisant par des outils statistiques l’effort d’échantillonnage réel pour obtenir une SAC théorique, libérée des aléas de l’ordre de prise en compte des données.La figure 1.3 montre l’accumulation des espèces pour les données de BCI.\nUne SAC peut être tracée en fonction de la surface, du nombre d’individus ou du nombres de placettes d’échantillonnage, selon les besoins.Code R pour réaliser la figure 1.3 :Les courbes d’accumulation peuvent aussi concerner la diversité (voir le chapitre ??), mesurée au-delà du nombre d’espèces.Plus généralement, une courbe aire-espèces (SAR : Species Area Relationship) représente le nombre d’espèces observées en fonction de la surface échantillonnée (figure ??).\nIl existe plusieurs façons de prendre en compte cette relation (Scheiner 2003), classables en deux grandes familles (Dengler 2009) :Dans une SAR au sens strict, chaque point représente une communauté.\nLa question traitée est la relation entre le nombre d’espèces et la taille de chaque communauté, en lien avec des processus écologiques ;Une courbe d’accumulation (SAC) ne représente que l’effet statistique de l’échantillonnage.\nPour éviter toute confusion, le terme SAR ne doit pas être utilisé pour décrire une SAC.","code":"\nlibrary(\"vegan\")\ndata(BCI)\n# Chaque parcelle (ligne) cumule ses abondances à la précédente\ncumul <- apply(BCI, 2, cumsum)\n# Le nombre d'espèces de chaque parcelle est cumulé \nRichesse <- apply(cumul, 1, function(x) sum(x > 0))\nggplot(\n  data.frame(\n    A = 0:50, \n    S = c(0, Richesse)\n  )\n) +\n  geom_line(aes(x = A, y = S)) +\n  labs(x = \"Surface (ha)\")"},{"path":"chap-Notions.html","id":"diversité-asymptotique","chapter":"1 Notions de Diversité","heading":"1.4 Diversité asymptotique","text":"Augmenter l’effort d’échantillonnage peut permettre d’atteindre un stade où la diversité n’augmente plus : sa valeur est appelée diversité asymptotique.\nDans des communautés très diverses comme les forêts tropicales, la diversité asymptotique ne peut en général pas être observée sur le terrain à cause de la variabilité de l’environnement : l’augmentation de la surface inventoriée amène à échantillonner dans des communautés différentes avant d’atteindre la diversité asymptotique de la communauté étudiée.\nLa diversité asymptotique est donc celle d’une communauté théorique qui n’existe généralement pas.\nEn d’autres termes, c’est la diversité d’une communauté dont l’inventaire disponible serait un échantillon représentatif.Evaluer la diversité asymptotique nécessite d’utiliser des estimateurs de diversité, dont la précision dépend de l’exhaustivité de l’échantillonnage.\nLa diversité peut aussi être estimée pour un effort donné : un hectare de forêt ou 5000 arbres par exemple, ou encore un taux de couverture choisi, qui décrit mieux la qualité de l’échantillonnage.","code":""},{"path":"chap-Notions.html","id":"sec-Couverture","chapter":"1 Notions de Diversité","heading":"1.5 Couverture","text":"Le taux de couverture (sample coverage) de l’échantillon est la proportion des espèces découvertes,\n\\[\\begin{equation}\n  \\tag{1.1}\n  C = \\sum^S_{s=1}{{\\mathbf 1}\\left( n_s > 0 \\right) p_s},\n\\end{equation}\\]où \\({\\mathbf 1}(\\cdot)\\) est la fonction indicatrice.\nSon complément à 1 est appelé déficit de couverture (coverage deficit).Le déficit de couverture est la probabilité qu’un individu tiré au hasard dans la communauté appartienne à une espèce absente de l’échantillon inventorié.\nC’est donc aussi la probabilité qu’un individu ajouté à l’inventaire lui ajoute une nouvelle espèce (Good 1953).\nLa pente de la courbe d’accumulation donnant l’espérance du nombre d’espèces en fonction du nombre d’individus (courbe de raréfaction de la figure ??) est donc égale au déficit de couverture (Chao Jost 2012) :\\[\\begin{equation}\n  \\tag{1.2}\n  1 - {\\mathbb E}\\left[ C\\left( n \\right) \\right] = {\\mathbb E}\\left[ S\\left( n + 1 \\right) \\right] - {\\mathbb E}\\left[ S\\left( n \\right) \\right],\n\\end{equation}\\]où \\(C(n)\\) est le taux de couverture d’un échantillon de taille \\(n\\) et \\(S(n)\\) le nombre d’espèces découvertes dans cet échantillon.Le taux de couverture augmente avec l’effort d’échantillonnage.\nPlus il est élevé, meilleures seront les estimations de la diversité : la diversité asymptotique est obtenue quand il atteint 1.\nLes estimateurs de la diversité asymptotique développés plus loin reposent largement sur cette notion pour la correction du biais d’échantillonnage (Dauby Hardy 2012), c’est-à-dire la sous-estimation systématique de la diversité due aux espèces non observées, qui est un des éléments du biais d’estimation.Pour comparer la diversité non asymptotique de deux communautés avec le même effort d’échantillonnage, Chao Jost (2012) montrent que le taux de couverture plutôt que la taille de l’échantillon doit être identique.","code":""},{"path":"chap-Notions.html","id":"formule-des-fréquences-de-good-turing","chapter":"1 Notions de Diversité","heading":"1.5.1 Formule des fréquences de Good-Turing","text":"La relation fondamentale entre les fréquences des espèces dans un échantillon est due à Turing et été publiée par Good (1953).\nEn absence de toute information sur la loi de distribution des espèces, en supposant seulement que les individus sont tirés indépendamment les uns des autres selon une loi multinomiale respectant ces probabilités, la formule de Good-Turing relie la probabilité attendue \\({\\mathbb E}(p_\\nu)\\) d’une espèce représentée par \\(\\nu\\) individus au rapport entre les nombres d’espèces représentées \\(\\nu+1\\) fois et \\(\\nu\\) fois :\\[\\begin{equation}\n  \\tag{1.3}\n  {\\mathbb E}\\left( p_\\nu \\right)\n  \\approx \\frac{(\\nu + 1)}{n} \\frac{{\\mathbb E}\\left( f_{\\nu+1} \\right)}{{\\mathbb E}\\left( f_\\nu \\right)}.\n\\end{equation}\\]La variance de \\(p_\\nu\\) est connue :\\[\\begin{equation}\n  \\tag{1.4}\n  \\operatorname{Var}\\left( p_\\nu \\right)\n  \\approx {\\mathbb E}\\left( p_\\nu \\right) \\left[ {\\mathbb E}\\left( p_{\\nu + 1} \\right) - {\\mathbb E}\\left( p_\\nu \\right) \\right].\n\\end{equation}\\]Elle est petite en comparaison de l’espérance.Le nombres d’espèces observées \\(\\nu\\) et \\(\\nu + 1\\) fois varient selon l’échantillonnage.\nLa relation de Good-Turing concerne leur espérance mais comme ne dispose en général que d’un seul inventaire, les espérances \\({\\mathbb E}(f_\\nu)\\) et \\({\\mathbb E}(f_{\\nu + 1})\\) sont remplacées par les valeurs observées.\nDe même, chacune des espèces observées \\(\\nu\\) fois une probabilité différente : la relation ne permet pas de prédire précisément, pour un échantillon, les probabilités de chaque espèce.Ces relations sont le fondement de plusieurs estimateurs de biodiversité présentés plus loin.\nLes singletons (\\(f_{1}\\): le nombre d’espèces observées une seule fois) et les doubletons (\\(f_{2}\\): le nombre d’espèces observées deux fois) ont une importance centrale.\nPour \\(\\nu=1\\), par exemple \\(\\alpha_1 = 2 f_{2}/(nf_{1})\\): la fréquence d’une espèce typiquement représentée par un singleton est proportionnelle au rapport entre le nombre des doubletons et des singletons.\nCet estimateur de probabilité est meilleur que l’estimateur naïf \\(1/n\\): en d’autres termes, la distribution des fréquences observées permet d’estimer les probabilités de façon non triviale.La relation été précisée (Chiu et al. 2014, eq. 6 et 7a) en limitant les approximations dans les calculs.\nLa seule approximation nécessaire est que les probabilités des espèces représentées le même nombre de fois \\(\\nu\\) varient peu et puissent être considérées toutes égales à \\({\\mathbb E}(p_\\nu)\\), ce qui est acceptable puisque la variance de \\(p_\\nu\\) est petite.\npeut alors estimer directement\n\\[\\begin{equation}\n  \\tag{1.5}\n   \\hat{p_\\nu}\n   = \\frac{\\left( \\nu + 1 \\right) f_{\\nu + 1}}{\\left(n - \\nu \\right) f_{\\nu} + \\left(\\nu + 1 \\right) f_{\\nu + 1}}\n\\end{equation}\\]en remplaçant les espérances par les valeurs observées.Ce nouvel estimateur est à la base de l’estimateur de Chao amélioré et des estimateurs d’entropie de Chao et Jost (sections 3.3.2 et ??).","code":""},{"path":"chap-Notions.html","id":"estimation-du-taux-de-couverture","chapter":"1 Notions de Diversité","heading":"1.5.2 Estimation du taux de couverture","text":"En posant \\(\\nu=0\\) dans l’équation (1.3), \\({\\mathbb E}(p_0) \\times f_{0} = \\pi_0\\), la probabilité totale des espèces non représentées, vaut approximativement \\(f_{1}/n\\).\nC’est l’estimateur de Good ou Good-Turing, parfois appelé abusivement “formule de Turing” (Z. Zhang Huang 2007) :\\[\\begin{equation}\n  \\tag{1.6}\n  \\hat{C} = 1 - \\frac{f_1}{n}.\n\\end{equation}\\]Cet estimateur est biaisé (Z. Zhang Huang 2007). En réalité,\n\\[\\begin{equation}\n  \\tag{1.7}\n  C = 1 - \\frac{{\\mathbb E}(f_1) - \\pi_1}{n}.\n\\end{equation}\\]L’estimateur de Good néglige le terme \\(\\pi_1\\), la somme des probabilités des espèces observées une fois.\nCe terme peut être estimé avec un biais plus petit.\nChao, Lee, Chen (1988) puis Z. Zhang Huang (2007) proposent l’estimateur suivant, qui utilise toute l’information disponible et le plus petit biais possible :\\[\\begin{equation}\n  \\tag{1.8}\n  \\hat{C} = 1 - \\sum^{n}_{\\nu = 1}{\\left( -1 \\right)}^{\\nu + 1}{\\binom{n}{\\nu}}^{-1}f_\\nu.\n\\end{equation}\\]Les termes de la somme décroissent très vite avec \\(\\nu\\).\nEn se limitant à \\(\\nu=1\\), l’estimateur se réduit à celui de Good.Esty (1983), complété par C.-H. Zhang Zhang (2009), montré que l’estimateur était asymptotiquement normal et calculé l’intervalle de confiance de \\(\\hat{C}\\):\\[\\begin{equation}\n  \\tag{1.9}\n  C = \\hat{C} \\pm t^{n}_{1 - \\alpha / 2} \\frac{\\sqrt{f_1 \\left( 1 - \\frac{f_{1}}{n} \\right) + 2f_2}}{n}.\n\\end{equation}\\]Où \\(t^{n}_{1 - \\alpha / 2}\\) est le quantile d’une loi de Student à \\(n\\) degrés de libertés au seuil de risque \\(\\alpha\\), classiquement 1,96 pour \\(n\\) grand et \\(\\alpha = 5\\%\\).Un autre estimateur est utilisé dans le logiciel SPADE (Chao Shen 2010) et son portage sous R, le package spadeR (Chao et al. 2016).\nIl est la base des estimateurs d’entropie de Chao et Jost (section ??).\nL’estimation de l’équation (1.7) donne la relation\n\\[\\begin{equation}\n  \\tag{1.10}\n  \\hat{C} = 1 - \\frac{f_{1} - \\hat{\\pi}_1}{n}.\n\\end{equation}\\], \\(\\hat{\\pi}_1 = f_{1} \\hat{p}_1\\).\n\\(p_1\\) peut être estimé par la relation de Good-Turing (1.5), en remplaçant \\(f_0\\) par l’estimateur Chao1 (3.5).\nAlors :\\[\\begin{equation}\n  \\tag{1.11}\n  \\hat{C}\n  = 1 - \\frac{f_1}{n}(1 - \\hat{p}_1)\n  = 1 - \\frac{f_1}{n}\\left[ \\frac{\\left( n - 1 \\right) f_1}{\\left( n - 1 \\right) f_1 + 2f_2} \\right].\n\\end{equation}\\]Dans le package divent, la fonction coverage calcule les trois estimateurs (celui de Zhang et Huang par défaut) :Le taux de couverture de BCI est proche de 1 parce que l’inventaire couvre 50 ha.\nIl est moindre sur les 6.25 ha de la parcelle 6 de Paracou :Les estimateurs présentés ici supposent une population de taille infinie (de façon équivalente, les individus sont tirés avec remise).\nLe cas des populations de taille finie est traité par Chao Lin (2012) et Hwang, Lin, Shen (2014).","code":"\nlibrary(\"divent\")\nBCI %>% \n  colSums() %>% \n  coverage()## # A tibble: 1 × 2\n##   estimator  coverage\n##   <chr>         <dbl>\n## 1 ZhangHuang    0.999\nparacou_6_abd %>% \n  colSums() %>% \n  coverage()## # A tibble: 1 × 2\n##   estimator  coverage\n##   <chr>         <dbl>\n## 1 ZhangHuang    0.972"},{"path":"chap-Notions.html","id":"complétude","chapter":"1 Notions de Diversité","heading":"1.5.3 Complétude","text":"La complétude de l’échantillonnage est la proportion du nombre d’espèces observées : \\(f_{>0} / S\\).\nElle compte simplement les espèces et ne doit pas être confondue avec la couverture qui somme leurs probabilités : le taux de complétude est toujours très inférieur au taux de couverture parce que les espèces non échantillonnées sont les plus rares.La complétude du même échantillon d’arbres de forêt tropicale que dans l’exemple précédent peut être estimée en divisant le nombre d’espèces observées par le nombre d’espèces estimées (voir section 3.1).\nÀ BCI :À Paracou :","code":"\nbci_abd <- colSums(BCI)\n# Espèces observées\n(obs <- div_richness(bci_abd, estimator  = \"naive\"))## # A tibble: 1 × 3\n##   estimator order diversity\n##   <chr>     <dbl>     <int>\n## 1 naive         0       225\n# Richesse estimée\n(est <- div_richness(bci_abd))## # A tibble: 1 × 3\n##   estimator   order diversity\n##   <chr>       <dbl>     <dbl>\n## 1 Jackknife 1     0       244\n# Complétude\nobs$diversity / est$diversity## [1] 0.9221311\n# Espèces observées\n(obs <- div_richness(colSums(paracou_6_abd), estimator  = \"naive\"))## # A tibble: 1 × 3\n##   estimator order diversity\n##   <chr>     <dbl>     <int>\n## 1 naive         0       335\n# Richesse estimée\n(est <- div_richness(colSums(paracou_6_abd)))## # A tibble: 1 × 3\n##   estimator   order diversity\n##   <chr>       <dbl>     <dbl>\n## 1 Jackknife 2     0       473\n# Complétude\nobs$diversity / est$diversity## [1] 0.7082452"},{"path":"chap-Notions.html","id":"le-problème-de-lespèce","chapter":"1 Notions de Diversité","heading":"1.6 Le problème de l’espèce","text":"Évaluer la richesse spécifique suppose que les espèces soient définies clairement, ce qui n’est de toute évidence pas le cas (Casetta 2014).\nLe premier aspect du problème concerne la nature des espèces : réalité naturelle ou seulement représentation simplificatrice.\nUne analyse historique et philosophique en est faite par Richards (2010).\nL’autre aspect, avec des conséquences pratiques plus immédiates, concerne leur délimitation.\nMayden (1997) recense vingt-deux définitions différentes du concept d’espèce.\n(Wilkins2011?) estime qu’il n’y qu’un seul concept d’espèce mais sept définitions, c’est-à-dire sept façons de les identifier, et vingt-sept variations ou mélanges de ces définitions.La définition historique est celle de morphoespèce, qui classe les espèces selon leurs formes, supposées d’abord immuables.\nLa définition moderne la plus répandue est celle d’espèce biologique (Dobzhansky 1937) : un “groupe de populations naturelles isolées reproductivement les unes des autres” (Mayr 1942).\nLorsque les populations d’une espèce sont isolées géographiquement, leur capacité à se reproduire ensemble est toute théorique (et rarement vérifiée expérimentalement).\nDes populations allopatriques n’ont pas de flux de gènes réels entre elles et peuvent être considérées comme des espèces distinctes selon la définition d’espèce phylogénétique : “le plus petit groupe identifiable d’individus avec un pattern commun d’ancêtres et de descendants” (Cracraft 1983).\nC’est l’unité génétique détectée par la méthode du coalescent pour la délimitation des espèces (Sukumaran Knowles 2017).\nLe nombre d’espèces phylogénétiques est bien supérieur au nombre d’espèces biologiques.\nEnfin, Van Valen (1976) définit les espèces par la niche écologique qu’elles occupent (à partir de l’exemple des chênes blancs européens) plutôt que par les flux de gènes (permanents entre les espèces distinctes) : la définition écologique d’espèce est proche du concept de complexe d’espèces (ensemble d’espèces voisines échangeant des gènes, Pernès 1984).Le choix de la définition modifie considérablement sur la quantification de la richesse (Agapow et al. 2004).\nDes problèmes méthodologiques s’ajoutent aux problèmes conceptuels (Hey 2001) : la séparation ou le regroupement de plusieurs populations ou morphotypes en un nombre plus ou moins grand d’espèces est un choix qui reflète les connaissances du moment et peut évoluer (Barberousse Samadi 2014).L’impact du problème de l’espèce sur la mesure de la diversité reste sans solution à ce stade, si ce n’est d’utiliser les mêmes définitions si des communautés différentes doivent être comparées.\nL’approche phylogénétique (chapitre ??) permet de contourner le problème : si deux taxons très semblables apportent à peine plus de diversité qu’un seul taxon, le choix de les distinguer ou non n’est pas critique.","code":""},{"path":"sec-SAD.html","id":"sec-SAD","chapter":"2 Distribution de l’abondance des espèces (SAD)","heading":"2 Distribution de l’abondance des espèces (SAD)","text":"La distribution de l’abondance des espèces (SAD : Species Abundance Distribution) est la loi statistique qui donne l’abondance attendue de chaque espèce d’une communauté.\nLes espèces ne sont pas identifiées individuellement, mais par le nombre d’individus leur appartenant.\nFigure 2.1: Histogramme des fréquences (diagramme de Preston) des arbres du dispositif de Barro Colorado Island. En abscisse : le nombre d’arbres de chaque espèce (en logarithme) ; en ordonnée : le nombre d’espèces.\nElle peut être représentée sous la forme d’un histogramme des fréquences (diagramme de Preston (1948), figure 2.1) ou bien d’un diagramme rang-abondance (RAC : Rank Abundance Curve ou diagramme de Whittaker (1965), figure 2.2).\nLe RAC est souvent utilisé pour reconnaître des distributions connues.\nIzsák Pavoine (2012) ont étudié les propriétés des RAC pour les principales SAD.\nFigure 2.2: Diagramme rang-abondance (diagramme de Whittaker) des arbres du dispositif de Barro Colorado Island. Les points sont les données : en abscisse : le rang de l’espèce, à partir de la plus abondante ; en ordonnée : l’abondance de l’espèce. La courbe est l’ajustement d’une distribution log-normale.\nCode de la figure 2.1 :Code de la figure 2.2 :Les SAD sont traitées en détail par Magurran (1988) ou McGill et al. (2007).\nLes principales distributions, nécessaires à la compréhension de la suite sont présentées ici :La distribution en log-séries de Fisher, Corbet, Williams (1943) ;La distribution géométrique (Motomura 1932; Whittaker 1972) ;La distribution log-normale (Preston 1948) ;Le modèle Broken Stick (MacArthur 1957).Formellement, la distribution des probabilités des espèces, notées \\(p_s\\), est à établir.","code":"\nBCI_abd <- sort(colSums(BCI), decreasing = TRUE)\nggplot(data.frame(BCI_abd), aes(BCI_abd)) + \n  geom_histogram(\n    bins = nclass.Sturges(log(BCI_abd)), \n    color = \"black\", \n    fill = \"white\",\n    boundary = 0\n  ) +\n  scale_x_log10() +\n  labs(\n    x = \"Effectifs (échelle logarithmique)\", \n    y = \"Nombre d'espèces\"\n  )\nlibrary(\"divent\")\nBCI_abd %>% \n  as_abundances() %>% \n  autoplot(fit_rac = TRUE, distribution = \"lnorm\")"},{"path":"sec-SAD.html","id":"la-distribution-en-log-séries","chapter":"2 Distribution de l’abondance des espèces (SAD)","heading":"2.1 La distribution en log-séries","text":"Cette distribution est traitée en détail dans le chapitre ??.Le nombre d’espèces est lié au nombre d’individus par la relation \\({\\mathbb E}(S^n) = \\alpha \\ln(1 + n / \\alpha)\\) où \\(S^n\\) indique le nombre d’espèces observées dans un échantillon de \\(n\\) individus.\n\\(\\alpha\\) est le paramètre qui fixe la pente de la partie linéaire de la relation, valide dès que \\(n \\gg \\alpha\\), où le nombre d’espèces \\(S^n\\) augmente proportionnellement au logarithme du nombre d’individus \\(\\ln(n)\\).La distribution été obtenue à partir d’inventaires de communautés de papillons en Malaisie et en Angleterre.\nLe modèle est tombé en désuétude faute de confirmation empirique à l’échelle de la communauté, avant d’être remis en valeur par la théorie neutre (Stephen P. Hubbell 2001) dans lequel la distribution de la méta-communauté est en log-séries.","code":""},{"path":"sec-SAD.html","id":"la-distribution-broken-stick","chapter":"2 Distribution de l’abondance des espèces (SAD)","heading":"2.2 La distribution Broken Stick","text":"Si les espèces se partagent les ressources ou l’espace des niches, représentées par un bâton, par un processus de cassure aléatoire et simultanée (précisément, les \\(S-1\\) cassures du bâton sont distribuées uniformément sur sa longueur) et que leur abondance est proportionnelle à la quantité de ressources ou d’espace de niche obtenus, alors leur distribution suit le modèle Broken Stick de MacArthur (1957).Parmi les distributions classiques, c’est la plus équitable : la distribution uniforme des probabilités (\\(p_s = 1 / S\\) pour tout \\(s\\)) n’est jamais approchée.Elle est peu observée empiriquement.","code":""},{"path":"sec-SAD.html","id":"la-distribution-log-normale","chapter":"2 Distribution de l’abondance des espèces (SAD)","heading":"2.3 La distribution log-normale","text":"Dans une distribution log-normale, le logarithme des probabilités des espèces (notées \\(p_s\\) pour l’espèce \\(s\\)) suit une loi normale.\nL’écart-type \\(\\sigma\\) de cette distribution règle l’équitabilité de la distribution.\nSon espérance est obtenue à partir du nombre d’espèces et de \\(\\sigma\\), pour que la somme des probabilités égale 1.May (1975) explique cette distribution par le théorème de la limite centrale : la variable aléatoire valant 1 si un individu est de l’espèce \\(s\\) et 0 sinon est le produit de nombreuses variables de loi inconnues valant 1 en cas de succès (germination d’une graine, survie à de nombreux évènements…).\nLe logarithme de ce produit est une somme de variables aléatoire dont la loi est forcément normale par application du théorème de la limite centrale.La distribution est aussi le résultat d’un algorithme de bâton brisé (broken stick) hiérarchique (Bulmer 1974) :Si les ressources (représentées par un bâton) sont partagées une première fois aléatoirement, selon une loi quelconque,Si chaque bâton obtenu est partagé à nouveau selon le même procédé, et que l’opération est répétée un assez grand nombre de fois,Si l’abondance de chaque espèce est proportionnelle aux ressources dont elle dispose,Alors la distribution des espèces est log-normale.Ce mécanisme décrit assez bien un mécanisme de partage successif des ressources, par exemple entre groupes d’espèces de plus en plus petits, correspondant à des niches écologiques de plus en plus étroites.D’autres arguments existent dans la littérature.\nPar exemple, Engen Lande (1996) obtiennent une distribution normale à partir d’un modèle de dynamique des populations.La distribution log-normale décrit assez bien (mais pas exactement) une communauté locale dans le cadre de la théorie neutre (Stephen P. Hubbell 2001) comme le montre la figure 2.2.\nLe nombre d’espèces rares est un peu surestimé.\nLa distribution exacte est donnée par Volkov et al. (2003).","code":""},{"path":"sec-SAD.html","id":"la-distribution-géométrique","chapter":"2 Distribution de l’abondance des espèces (SAD)","heading":"2.4 La distribution géométrique","text":"Si les espèces se partagent les ressources selon un algorithme broken stick séquentiel (comme dans la distribution log-normale) mais de proportion fixe \\(0<k<1\\), alors la distribution obtenue est géométrique.\nLes abondances successives sont proportionnelles à \\(k, k(1-k), k(1-k)^2, \\dots, k(1-k)^s, \\dots, k(1-k)^S\\).Ce modèle été établi par Motomura (1932) cité par May (1975).\nSes propriétés ont été étudiées par Whittaker (1972).C’est la distribution qui traduit l’absence de relation entre la taille de l’échantillon et l’abondance des espèces (Pueyo, , Zillio 2007) : la distribution du logarithme de ses probabilités est uniforme.\nEn d’autre termes, l’ordre de grandeur de l’abondance d’une espèce est uniformément distribué.La distribution est observée dans les communautés pionnières (Bazzaz1975?), peu diverses, ou les communautés microbiennes (Haegeman et al. 2013).","code":""},{"path":"sec-SAD.html","id":"synthèse","chapter":"2 Distribution de l’abondance des espèces (SAD)","heading":"2.5 Synthèse","text":"\nFigure 2.3: Diagramme rang-fréquence des distributions de probabilité classiques. Toutes les distributions sont de 100 espèces. Les probabilités inférieures à \\(10^{-6}\\) ne sont pas affichées. Les paramètres choisis sont \\(\\alpha=11\\) pour la distribution log-séries, \\(k=0,2\\) pour la distribution géométrique et \\(\\sigma=2\\) pour la distribution log-normale.\nLa figure 2.3 est inspirée de la figure très connue de Magurran (1988).\nElle montre bien une gradation en termes de décroissance de probabilité entre des distributions de même richesse : de la plus équitable (broken stick) à la plus inéquitable (géométrique).\nElle doit être nuancée : la proportion \\(k\\) de la distribution géométrique fixe la pente de la droite qui la représente sur la figure.\n\\(k=10\\%\\) sur la figure : une valeur plus faible diminuerait la pente.\nDe même, l’écart-type de la distribution log-normale décrit sa dispersion.\nUne valeur supérieure augmenterait sa décroissance.Le code utilisé pour produire la figure 2.3 est le suivant :La simulation de ces quatre distributions peut être réalisée par la fonction rcommunity() du package divent, où l’argument distribution peut valoir “bstick”, “lnorm”, “geom” ou “lseries”.\nLa simulation des communautés autres que log-séries passe par le tirage des probabilités des espèces (le calcul est déterministe dans le cas de la distribution géométrique) puis le tirage d’un nombre d’individus dans une loi multinomiale respectant ces probabilités et l’effectif total.La fonction fit_rac() permet d’inférer les paramètres d’une distribution à partir d’un vecteur d’abondance.\nLa distribution correspondant au modèle estimé peut être affichée sur la figure Rang-Abondance (figure 2.1).Le package sads fournit les fonctions classiques de R (densité de probabilité, cumulative, quantile, simulation) pour les distributions utiles en écologie, au-delà de celles présentées ici.\nLa distribution de Volkov notamment peut être simulée.\nLes fonctions fitxxx() complètent la fonction fit_rac() de divent.\nEnfin, la fonction radfit() du package vegan ajuste aux données en même temps les distributions broken-stick (désignée par “Null”), géométrique (“Preemption”) et lognormale, inclut les distributions de Zipf et de Mandelbrot non traitées ici, mais ignore les log-séries.\nLes vraisemblances des différents modèles sont comparées pour choisir celui qui s’ajuste le mieux.Le code suivant montre comment ajuster une distribution log-normale aux données de BCI avec divent ou sads.L’ajustement du modèle de Volkov peut être comparé à celui d’une distribution log-normale.Graphiquement, l’ajustement est très proche mais la distribution de Volkov prévoit explicitement des effectifs égaux parce qu’entiers.Les vraisemblances sont proches.Les paramètres du modèle de communauté locale de la théorie neutre sont \\(\\theta\\), le “nombre fondamental de la biodiversité” égal à deux fois le nombre d’espèces apparaissant par pas de temps dans la méta-communauté, \\(m\\), le taux de migration, et \\(J\\), la taille de la communauté locale (qui n’est pas à proprement parler un paramètre mais une statistique décrivant les données).La différence entre les logarithmes de vraisemblance des deux modèles en faveur du modèle de Volkov, alors que le nombre de paramètres est le même.\nL’ajustement est donc meilleur mais la différence est petite et la complexité du modèle et des calculs pour l’estimer ne se justifient pas en général : le modèle de Volkov est très peu utilisé en pratique.","code":"\nlibrary(\"divent\")\n# Tirage d'une communauté en log-séries\nsize <- 1E5\nalpha <- 11\nspecies_number <- -alpha * log(alpha / (size + alpha))\nabd_lseries <- rlseries(species_number, size, alpha)\n# Part des ressources accaparées dans la distribution géométrique\nprob <- 0.2\n# Calcul des probabilités de la distribution géométrique\nprob_geom <- prob / (1 - (1 - prob)^species_number) * (1 - prob)^(0:(species_number - 1))\n# Dispersion de la loi lognormale\nsd <- 2\n# Tirage de S valeurs dans une loi lognormale\nabd_lnorm <- rlnorm(species_number, meanlog = 0, sdlog = sd)\n# Tirage des probabilités de la distribution broken stick\nprob_bstick <- c(cuts <- sort(stats::runif(species_number - 1)), 1) - c(0, cuts)\n# Graphique\ntibble(\n  rank = 1:species_number,\n  `Log-Séries` = sort(abd_lseries / sum(abd_lseries), decreasing = TRUE),\n  `Géometrique` = sort(prob_geom, decreasing = TRUE),\n  `Log-Normale` = sort(abd_lnorm / sum(abd_lnorm), decreasing = TRUE),\n  `Broken Stick` = sort(prob_bstick, decreasing = TRUE)) %>% \n  pivot_longer(cols = -rank) %>% \n  ggplot() +\n    geom_line(aes(x = rank, y = value, color = name)) +\n    scale_y_log10(limits = c(1E-6, NA)) +\n    labs(y = \"Probabilité\", color = \"Distribution\")\n# divent\nlibrary(\"divent\")\nfit_divent_lnorm <- fit_rac(BCI_abd, distribution = \"lnorm\")\n# Affichage des paramètres estimés\nfit_divent_lnorm$parameters## # A tibble: 1 × 2\n##      mu sigma\n##   <dbl> <dbl>\n## 1  3.14  1.79\n# sads\nlibrary(\"sads\")\n# Estimation. Les données sont tronquées: les espèces observées 0 fois ne sont pas comptées.\nfit_sads_lnorm <- fitlnorm(BCI_abd, trunc=0)\nfit_sads_lnorm@fullcoef##  meanlog    sdlog \n## 3.142695 1.787195\n#vegan\nlibrary(\"vegan\")\nfit_vegan_lnorm <- radfit(BCI_abd)\nfit_vegan_lnorm## \n## RAD models, family poisson \n## No. of species 225, total abundance 21457\n## \n##            par1      par2     par3    Deviance AIC     \n## Null                                  10261.14 11387.97\n## Preemption  0.034063                   3788.38  4917.21\n## Lognormal   3.3569    1.5738            744.30  1875.13\n## Zipf        0.14679  -0.94912          4335.50  5466.33\n## Mandelbrot  17.014   -2.0064   15.048   988.02  2120.85\n##            BIC     \n## Null       11387.97\n## Preemption  4920.63\n## Lognormal   1881.96\n## Zipf        5473.16\n## Mandelbrot  2131.10\n# Ajustement du modèle de Volkov\nfit_volkov <- fitvolkov(BCI_abd)\nfit_volkov@fullcoef##        theta            m            J \n## 4.767129e+01 9.238201e-02 2.145700e+04\n# Comparaison graphique des deux modèles. Log-normal en rouge.\nplot(as_abundances(BCI_abd), fit_rac = TRUE, distribution=\"lnorm\")\n# Volkov en vert\nlines(\n  sort(\n    rvolkov(\n      length(BCI_abd), \n      fit_volkov@fullcoef[1], \n      fit_volkov@fullcoef[2], \n      fit_volkov@fullcoef[3]\n    ), \n    decreasing=TRUE\n  ), \n  col=\"green\"\n)\n# Comparaison des vraisemblances\nfit_sads_lnorm@min## [1] 1157.013\nfit_volkov@min## [1] 1150.182"},{"path":"chap-MesuresNeutres.html","id":"chap-MesuresNeutres","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","text":"Les indices classiques de diversité sont ceux de Shannon et de Simpson, et la richesse spécifique.\nIls peuvent être estimés à partir des données d’inventaire.\nL’estimation de la richesse est particulièrement difficile et fait l’objet d’une abondante littérature : les estimateurs non-paramétriques (Chao et Jackknife) sont les plus utilisés.Les mesures classiques (Peet 1974) considèrent que chaque classe d’objets est différente de toutes les autres, sans que certaines soient plus ou moins semblables.\nDans ce chapitre, les classes seront des espèces.\nLes mesures sont qualifiées de neutres (species-neutral) au sens où elles ne prennent en compte aucune caractéristique propre des espèces.\nLa diversité neutre est souvent appelée diversité taxonomique (Devictor et al. 2010; Stegen Hurlbert 2011), même si le terme peut prêter à confusion avec la diversité phylogénétique, quand la phylogénie se réduit à une taxonomie (Clarke Warwick 2001; Ricotta Avena 2003).Ce type de mesure n’de sens qu’à l’intérieur d’un taxocène bien défini : sommer un nombre d’espèces d’insectes à un nombre d’espèces de mammifères peu d’intérêt.\nCes méthodes ne sont donc pas forcément les plus adaptées à la conservation : à grande échelle, des indicateurs de biodiversité (Balmford, Green, Jenkins 2003) peuvent être plus pertinents.\nD’autre part, les communautés sont considérées comme limitées, avec un nombre d’espèces fini : la courbe d’accumulation des espèces atteint donc théoriquement une asymptote quand l’effort d’inventaire est suffisant.\nCette approche est opposée à celle, traitée dans les chapitres ?? et suivants, qui considère que la diversité augmente indéfiniment avec la surface (Williamson, Gaston, Lonsdale 2001), que ce soit par changement d’échelle (élargir l’inventaire ajoute de nouvelles communautés) ou, plus théoriquement, parce que les communautés réelles sont considérées comme un tirage aléatoire parmi une infinités d’espèces (Fisher, Corbet, Williams 1943).Les mesures présentées ici sont les plus utilisées : richesse, indices de Shannon et de Simpson, et l’indice de Hurlbert.\nElles sont sujettes à des biais d’estimation (Mouillot Leprêtre 1999), notamment (mais pas seulement) à cause des espèces non échantillonnées.Au chapitre suivant, l’entropie HCDT permettra d’unifier ces mesures et les nombres de Hill, et de leur donner un sens intuitif.","code":""},{"path":"chap-MesuresNeutres.html","id":"sec-Richesse","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.1 Richesse spécifique","text":"La richesse est tout simplement le nombre d’espèces présentes dans le taxocène considéré.\nC’est la mesure conceptuellement la plus simple mais pratiquement la plus délicate dans des systèmes très riches comme les forêts tropicales : même avec des efforts d’inventaire considérables, il n’est en général pas possible de relever toutes les espèces rares, ce qui implique de recourir à des modèles mathématiques pour en estimer le nombre.ne fait pas de supposition sur la forme de la SAD (voir section 2) quand utilise des méthodes d’estimation non paramétriques.\nLes estimateurs les plus connus sont ceux de Chao (1984) et le jackknife (Burnham Overton 1979).Une alternative consiste à inférer à partir des données les paramètres d’une SAD choisie, et particulièrement le nombre total d’espèces.\nCette approche est bien moins répandue parce qu’elle suppose le bon choix du modèle et est beaucoup plus intensive en calcul.\nIl n’existe pas de meilleur estimateur universel (O’Hara 2005) et il peut être efficace d’utiliser plusieurs méthodes d’estimation de façon concurrente sur les mêmes données (Basset et al. 2012).","code":""},{"path":"chap-MesuresNeutres.html","id":"techniques-destimation-non-paramétrique","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.1.1 Techniques d’estimation non paramétrique","text":"Dans le cadre d’un échantillonnage de \\(n\\) individus, observe \\(f_{>0}\\) espèces différentes parmi les \\(S\\) existantes.\nChaque individu une probabilité \\(p_s\\) d’appartenir à l’espèce \\(s\\).ne sait rien sur la loi des \\(p_s\\).\nsait seulement, comme les individus sont tirés indépendamment les uns des autres, que l’espérance du nombre \\(n_s\\) d’individus de l’espèce \\(s\\) observé dans l’échantillon est \\(np_s\\).\nLa probabilité de ne pas observer l’espèce est \\((1-p_s)^n\\).Pour les espèces fréquentes, \\(np_s\\) est grand, et les espèces sont observées systématiquement.\nLa difficulté est due aux espèces pour lesquelles \\(np_s\\), l’espérance du nombre d’observations, est petit.\nLa probabilité de les observer est donnée par la loi binomiale : si \\(np_s\\) est proche de 0, la probabilité d’observer un individu est faible.Les estimateurs non paramétriques cherchent à tirer le maximum d’information de la distribution des abondances \\(n_s\\) pour estimer le nombre d’espèces non observées.\nUne présentation détaillée du problème et des limites à sa résolution est fournie par Mao Colwell (2005) qui concluent notamment que les estimateurs ne peuvent fournir qu’une borne inférieure de l’intervalle des possibles valeurs du nombre réel d’espèces.","code":""},{"path":"chap-MesuresNeutres.html","id":"chao1-et-chao2","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.1.1.1 Chao1 et Chao2","text":"Chao (1984) estime le nombre d’espèces non observées à partir de celles observées 1 ou 2 fois.Dans un échantillon de taille \\(n\\) résultant d’un tirage indépendant des individus, la probabilité que l’espèce \\(s\\) soit observée \\(\\nu\\) fois est obtenue en écrivant la probabilité de tirer dans l’ordre \\(\\nu\\) fois l’espèce \\(s\\) puis \\(n-\\nu\\) fois une autre espèce, multiplié par le nombre de combinaisons possible pour prendre en compte l’ordre des tirages :\n\\[\\begin{equation}\n  \\tag{3.1}\n  p_{s, \\nu}(n) = \\binom{n}{\\nu} {p_s^\\nu \\left( 1 - p_s \\right)^{n - \\nu}}.\n\\end{equation}\\]L’espérance du nombre d’espèces observées \\(\\nu\\) fois, \\({\\mathbb E}(f_{\\nu})\\), est obtenue en sommant pour toutes les espèces la probabilité de les observer \\(\\nu\\) fois :\n\\[\\begin{equation}\n  \\tag{3.2}\n  {\\mathbb E}\\left( f_{\\nu} \\right) = \\binom{n}{\\nu} \\sum_s{p_s^\\nu \\left( 1 - p_s \\right)^{n - \\nu}}.\n\\end{equation}\\]Le carré de la norme du vecteur en \\(S\\) dimensions dont les coordonnées sont \\((1 - p_s)^{n / 2}\\) est\n\\[\\sum_s{(1 - p_s)^n},\\]\nc’est-à-dire \\({\\mathbb E}(f_{0})\\), l’espérance du nombre d’espèces non observées.\nCelui du vecteur de coordonnées \\(p_s (1 - p_s)^{n / 2 - 1}\\) est\n\\[\\sum_s{p_s^2 (1 - p_s)^{n - 2}} = \\frac{2}{n (n - 1)}{\\mathbb E}(f_{2}).\\]\nEnfin, le produit scalaire des deux vecteurs vaut\n\\[\\sum_s{p_s (1 - p_s)^{n - 1}} = \\frac{1}{n}{\\mathbb E}(f_{1}).\\]L’inégalité de Cauchy-Schwarz (le produit scalaire est inférieur au produit des normes des vecteurs) peut être appliquée aux deux vecteurs (tous les termes sont au carré) :\n\\[\\begin{equation}\n  \\tag{3.3}\n  \\left[ \\sum_s{(1 - p_s)^n} \\right] \\left[ \\sum_s{p_s^2 (1 - p_s)^{n-2}} \\right]\n   \\ge \\left[ \\sum_s{p_s (1 - p_s)^{n-1}} \\right]^2,\n\\end{equation}\\]d’où\n\\[\\begin{equation}\n  \\tag{3.4}\n  {\\mathbb E}(f_{0})\n  \\ge \\frac{n - 1}{n}\\frac{\\left[ {\\mathbb E}(f_{1}) \\right]^2}{2 {\\mathbb E}(f_{2})}.\n\\end{equation}\\]L’estimateur est obtenu en remplaçant les espérances par les valeurs observées :\\[\\begin{equation}\n  \\tag{3.5}\n  {\\hat{S}}_\\mathit{Chao1}\n   = f_{>0} + \\frac{\\left(n - 1 \\right){\\left( f_{1} \\right)}^2}{2n {f_{2}}},\n\\end{equation}\\]où \\(f_{>0}\\) est le nombre d’espèces différentes observé.Il s’agit d’un estimateur minimum : l’espérance du nombre d’espèces est supérieure ou égale au nombre estimé.Béguinot (2014) montré que l’estimateur est sans biais si le nombre d’espèces non observées décroît exponentiellement avec la taille de l’échantillon :\n\\[\\begin{equation}\n  \\tag{3.6}\n  f_{0} = S e^{-kn},\n\\end{equation}\\]\noù \\(k\\) est un réel strictement positif.\nCette relation est cohérente avec un échantillonnage poissonien dans lequel la densité des individus est constante : voir le chapitre ??.Si aucune espèce n’est observée deux fois, l’estimateur est remplacé par\n\\[\\begin{equation}\n  \\tag{3.7}\n  {\\hat{S}}_\\mathit{Chao1} = f_{>0} + \\frac{\\left( n - 1 \\right){f_{1}}\\left( f_{1} - 1 \\right)}{2n}.\n\\end{equation}\\]Si \\(n\\) n’est pas trop petit, les approximations suivantes sont possibles :\\[\\begin{equation}\n  \\tag{3.8}\n  \\hat{S}_\\mathit{Chao1}\n   = {f_{>0}} + \\frac{{\\left( f_{1} \\right)}^2}{2f_{2}}.\n\\end{equation}\\]Si aucune espèce n’est observée deux fois, l’estimateur est remplacé (Chao 2004) par\\[\\begin{equation}\n  \\tag{3.9}\n  {\\hat{S}}_\\mathit{Chao1}\n  = {f_{>0}} + {f_{1}\\left( f_{1} - 1 \\right)} / {2}.\n\\end{equation}\\]La variance de l’estimateur est connue, mais pas sa distribution :\\[\\begin{equation}\n  \\tag{3.10}\n  \\operatorname{Var}{\\left( {\\hat{S}}_\\mathit{Chao1} \\right)}\n  = {f_{2}}\\left[\n      \\frac{1}{2}{\\left( \\frac{f_{1}}{f_{2}} \\right)}^2\n      + {\\left( \\frac{f_{1}}{f_{2}} \\right)}^3\n      + \\frac{1}{4}{\\left( \\frac{f_{1}}{f_{2}} \\right)}^4\n    \\right].\n\\end{equation}\\]Si aucune espèce n’est observée deux fois :\\[\\begin{equation}\n  \\tag{3.11}\n  \\operatorname{Var}{\\left( {\\hat{S}}_\\mathit{Chao1} \\right)}\n  = \\frac{f_{1}\\left(f_{1}-1\\right)}{2}\n    + \\frac{f_{1}{\\left( 2f_{1} -1 \\right)}^2}{4}\n    + \\frac{{\\left( f_{1} \\right)}^4}{4f_{>0}}.\n\\end{equation}\\]Chao (1987) donne une approximation de l’intervalle de confiance à 95 % en assumant une distribution normale :\\[\\begin{equation}\n  \\tag{3.12}\n  f_{>0} + \\frac{{\\hat{S}}_\\mathit{Chao1} - {f_{>0}}}{c}\n  \\le S\n  \\le {f_{>0}} + \\left( {\\hat{S}}_\\mathit{Chao1} - {f_{>0}} \\right)c,\n\\end{equation}\\]où\\[\\begin{equation}\n  \\tag{3.13}\n  c = e^{\n    t^{n}_{1 - \\alpha / 2} \\sqrt{\n      \\ln\\left( 1 + \\frac{\\operatorname{Var}\\left( {\\hat{S}}_\\mathit{Chao1} \\right)}{{\\left( {\\hat{S}}_\\mathit{Chao1} - {f_{>0}} \\right)}^2} \\right)\n    }\n  }.\n\\end{equation}\\]Eren et al. (2012, eq. 8) calculent un intervalle de confiance qui est plus petit quand la valeur maximum théorique du nombre d’espèces est connue, ce qui est rarement le cas en écologie.Chao (1987) propose un estimateur du nombre d’espèces appliqué aux données de présence-absence (un certain nombre de relevés contiennent seulement l’information de présence ou absence de chaque espèce), appelé Chao2. Il est identique à Chao1 mais \\(n\\) est le nombre de relevés, en général trop petit pour appliquer l’approximation de Chao1.Chiu et al. (2014) améliorent l’estimateur en reprenant la démarche originale de Chao mais en utilisant un estimateur plus précis du taux de couverture, (1.11) au lieu de (1.6) :\\[\\begin{equation}\n  \\tag{3.14}\n  {\\hat{S}}_\\mathit{iChao1}\n  = {\\hat{S}}_\\mathit{Chao1}\n    + \\frac{f_{3}}{4f_{4}}\n    \\,\\max\\left( f_{1} - \\frac{f_{2}f_{3}}{2f_{4}} ; 0 \\right).\n\\end{equation}\\]Chao et al. (2017) étendent l’applicabilité de l’estimateur Chao2 à des données dans lesquelles les espèces sont notées uniquement comme singletons ou doubletons et plus, sans distinction entre doubletons et espèces plus fréquentes.\nUne relation entre le nombre de doubletons et les données disponibles est fournie ; sa résolution numérique (le code R nécessaire est disponible avec l’article) permet d’estimer \\(f_{2}\\) et de l’injecter dans l’estimateur Chao2.","code":""},{"path":"chap-MesuresNeutres.html","id":"lestimateur-ace","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.1.1.2 L’estimateur ACE","text":"Chao Lee (1992) développent l’estimateur ACE (Abundance-based coverage estimator) à travers l’estimation du taux de couverture \\(C\\).\nL’estimateur ACE utilise toutes les valeurs de \\(f_\\nu\\) correspondant aux espèces rares : concrètement, la valeur limite de \\(\\nu\\) notée \\(\\kappa\\) est fixée arbitrairement, généralement à 10.L’estimateur prend en compte le coefficient de variation de la distribution des fréquences (\\({\\hat{p}}_s\\)) : plus les probabilités sont hétérogènes, plus le nombre d’espèces non observées sera grand.\nFinalement :\\[\\begin{equation}\n  \\tag{3.15}\n  \\hat{S}_{\\mathit{ACE}}\n  = f_{>\\kappa} + \\frac{f_{\\le\\kappa}}{\\hat{C}_\\mathit{rare}} + \\frac{f_{1}}{{\\hat{C}}_\\mathit{rare}}{\\hat{\\gamma}}_\\mathit{rare}.\n\\end{equation}\\]\\(f_{>\\kappa}\\) est le nombre d’espèces dites abondantes, observées plus de \\(\\kappa\\) fois, \\(f_{\\le\\kappa}\\) le nombre d’espèces dites rares, observées \\(\\kappa\\) fois ou moins.\n\\(\\hat{C}_\\mathit{rare}\\) est le taux de couverture ne prenant en compte que les espèces rares.L’estimateur du coefficient de variation au carré est\\[\\begin{equation}\n  \\tag{3.16}\n  \\hat{\\gamma}^{2}_\\mathit{rare}\n  = \\max\\left(\n    \\frac{\n      f_{\\le\\kappa} \\sum^{\\kappa}_{\\nu=1}{\\nu\\left( \\nu - 1 \\right){f_\\nu}}\n    }{\n      \\hat{C}_\\mathit{rare} \\left( \\sum^{\\kappa}_{\\nu = 1}{\\nu f_{\\nu}} \\right) \\left( \\sum^{\\kappa}_{\\nu = 1}{\\nu f_{\\nu}} - 1 \\right)\n    } - 1 ; 0\n  \\right).\n\\end{equation}\\]Lorsque l’hétérogénéité est très forte, un autre estimateur est plus performant :\\[\\begin{equation}\n  \\tag{3.17}\n  \\tilde{\\gamma}^{2}_\\mathit{rare}\n  = \\max\\left(\n    {\\hat{\\gamma}}^2_\\mathit{rare} \\left(\n      1 + \\frac{\n        \\left( 1 - {\\hat{C}}_\\mathit{rare} \\right) \\sum^{\\kappa}_{\\nu = 1}{\\nu\\left( \\nu - 1 \\right){f_\\nu}}\n      }{\n        {\\hat{C}}_\\mathit{rare} \\left( \\sum^{\\kappa}_{\\nu = 1}{\\nu f_\\nu - 1} \\right)\n      }\n    \\right) ; 0\n  \\right).\n\\end{equation}\\]Chao Shen (2010) conseillent d’utiliser le deuxième estimateur dès que \\({\\hat{\\gamma}}^2_\\mathit{rare}\\) dépasse 0,8.\nL’estimateur ACE donne normalement une valeur plus grande que Chao1.\nSi ce n’est pas le cas, la limite des espèces rares \\(\\kappa\\) doit être augmentée.","code":""},{"path":"chap-MesuresNeutres.html","id":"lestimateur-jackknife","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.1.1.3 L’estimateur jackknife","text":"La méthode jackknife pour objectif de réduire le biais d’un estimateur en considérant des jeux de données dans lesquels supprimé un certain nombre d’observations (ce nombre est l’ordre de la méthode).\nBurnham et Overton (1978, 1979) ont utilisé cette technique pour obtenir des estimateurs du nombre d’espèces, appelés jackknife à l’ordre \\(j\\), prenant en compte les valeurs de \\(f_1\\) à \\(f_j\\).\nLes estimateurs du premier et du deuxième ordre sont les plus utilisés en pratique :\\[\\begin{equation}\n  \\tag{3.18}\n  \\hat{S}_\\mathit{J1} = {f_{>0}} + \\frac{\\left( n - 1 \\right) f_1}{n},\n\\end{equation}\\]\\[\\begin{equation}\n  \\tag{3.19}\n  \\hat{S}_\\mathit{J2}\n  = {f_{>0}} + \\frac{\\left( 2n - 3 \\right) f_1}{n}\n    - \\frac{{\\left( n - 2 \\right)}^2 f_2}{n \\left( n - 1 \\right)}.\n\\end{equation}\\]\\[\\begin{equation}\n  \\tag{3.20}\n  \\hat{S}_\\mathit{J3}\n  = {f_{>0}} + \\frac{\\left( 3n - 6 \\right) f_1}{n}\n    - \\frac{\\left( 3n^2 - 15n +19 \\right) f_2}{n \\left( n - 1 \\right)}\n    + \\frac{{\\left( n - 3 \\right)}^3 f_3}{n \\left( n - 1 \\right) \\left( n - 2 \\right)}.\n\\end{equation}\\]Augmenter l’ordre du jackknife diminue le biais mais augmente la variance de l’estimateur.Chao (1984) montré que les estimateurs jackknife pouvaient être retrouvés par approximation de l’indice Chao1.La variance du jackknife d’ordre 1 est (Heltshe Forrester 1983)\n\\[\\begin{equation}\n  \\tag{3.21}\n  \\operatorname{Var}{\\left( \\hat{S}_\\mathit{J1} \\right)}\n  = \\frac{n - 1}{n} \\left( \\sum_{j = 1}^{n}{j^2 f_j} - \\frac{f_{>0}^2}{n} \\right).\n\\end{equation}\\]L’estimateur est construit à partir de l’hypothèse selon laquelle le nombre d’espèces non observées est de la forme\n\\[f_0(n) = \\sum_{= 1}^{\\infty}{\\frac{a_i}{n^}},\\]où la notation \\(f_0(n)\\) est utilisée pour expliciter sa dépendance à l’effort d’échantillonnage.Pour cette raison, Cormack (1989) affirme qu’il n’pas de support théorique solide.\nL’espérance du nombre d’espèces non observées est (eq. (3.2)) \\(\\sum_s{(1 - p_s)^n}\\), qui décroît beaucoup plus rapidement que \\(\\sum_{}{{a_i}/{n^}}\\): l’hypothèse est bien fausse.\nEn revanche, pour une gamme de \\(n\\) fixée (de la taille de l’inventaire à une taille suffisante pour approcher la richesse asymptotique par exemple), il est toujours possible d’écrire le nombre d’espèces non observées sous la forme d’une série de puissances négatives de \\(n\\), comme dans l’illustration ci-dessous.Une communauté log-normale, similaire à BCI (300 espèces, écart-type égal à 2) est simulée et un échantillon de 1000 individus est tiré.L’échantillon est présenté en figure 3.1.Code de la figure 3.1 :\nFigure 3.1: Echantillon de 1000 individus tiré dans une communauté log-normale.\nIl est possible de vérifier que l’espérance du nombre d’espèces non observées correspond bien à la moyenne des observations.Le nombre d’espèces non observées peut être écrit sous la forme d’une série de puissances négatives de \\(n\\), comme le prévoit le jackknife, entre deux valeurs de \\(n\\) fixées.Le nombre d’espèces non observées, qui est le biais de l’estimateur de la richesse, est présenté en figure 3.2.La courbe peut être approchée par une série de puissances négatives de \\(n\\) dont quelques termes sont présentés sur la figure.Les termes \\(a_i\\) de la série de puissances négatives sont estimées par des modèles linéaires.\nl’ordre 1, le modèle lm1 fournit une approximation grossière du nombre d’espèces non observées avec un seul terme (\\(f_0(n) \\approx a_1 / n\\)).\nLe modèle s’appproche de plus en plus des données en augmentant le nombre de terme.\nLe modèle lm4 contient 4 termes \\(a_1\\) à \\(a_4\\) :\npartir de 6 termes, les valeurs du biais d’estimation sont presque parfaitement estimées.\nFigure 3.2: Nombre d’espèces non observées dans un échantillon de taille croissante et sa décomposition en séries de puissances négatives de \\(n\\). Le nombre d’espèces non observées est représenté par la courbe continue. Les séries de puissances négatives d’ordre 1, 2 et 4, notées lm1 à lm4, sont représentées en pointillés. Les courbes d’ordre 6 et plus sont confondues avec la courbe noire.\nCode de la figure 3.2 :L’ajustement est possible pour des valeurs de \\(n\\) différentes mais les coefficients \\(a_i\\) sont alors différents : la forme du biais n’est valide que pour une gamme de valeurs de \\(n\\) fixée.Béguinot (2016) apporte un autre argument important en faveur du jackknife.\nÀ condition que \\(n\\) soit suffisamment grand, l’estimateur du nombre d’espèces non observées est une fonction linéaire du nombre d’espèces observées \\(\\nu\\) fois : \\(f_1\\) pour le jackknife 1, \\(2 f_1 - f_2\\) pour le jackknife 2 et ainsi de suite pour les ordres suivants, contrairement à l’estimateur de Chao.\nGrâce à cette propriété, l’estimateur du jackknife est additif quand plusieurs groupes d’espèces disjoints sont pris en compte : l’estimation du nombre d’espèces de papillons et de scarabées inventoriées ensemble est égale à la somme des estimations des deux groupes inventoriés séparément.\nCe n’est pas le cas pour l’estimateur de Chao.L’estimateur du jackknife est très utilisé parce qu’il est efficace en pratique, notamment parce que son ordre peut être adapté aux données.","code":"\n# Ecart-type\nsdlog <- 2\n# Nombre d'espèces\nS <- 300\n# Tirage des probabilités log-normales\nlnorm_abd <- rlnorm(S, 0, sdlog)\nlnorm_prob <- lnorm_abd / sum(lnorm_abd)\n# Taille de l'échantillon\nn <- 1000\n# Tirage d'un échantillon\nlibrary(\"divent\")\nabundances <- rcommunity(1, size = n, prob = lnorm_prob)\nautoplot(abundances, fit_rac = TRUE, distribution=\"lnorm\")\n# Espérance des espèces non vues\nE0 <- (1 - lnorm_prob)^n\n(f0 <- sum(E0))## [1] 169.7165\n# Tirage de 1000 échantillons, nombre moyen d'espèces observées\n(s_obs <- mean(colSums(rmultinom(1000, size = n, prob = lnorm_prob) > 0)))## [1] 130.37\n# Vérification: nombre d'espèces observées en moyenne et non observées\ns_obs + f0## [1] 300.0865\n# Nombre total d'espèces dans la communauté\n(S <- length(lnorm_prob))## [1] 300\n# Echantillonnage de 500 à 5000 individus\nn_seq <- 500:5000\n# Calcul du nombre d'espèces non observées\nbias <- sapply(n_seq, function(n) sum((1 - lnorm_prob)^n))\n# Ordre 1\nlm1 <- lm(bias ~ 0 + I(1  /n_seq))\n# Ordre 2\nlm2 <- lm(bias ~ 0 + I(1 / n_seq) + I(1 / n_seq^2))\n# Ordre 4\nlm4 <- lm(\n  bias ~ 0 + I(1 / n_seq) + I(1 / n_seq^2) + I(1 / n_seq^3) + I(1 / n_seq^4)\n)\nlm4$coefficients##    I(1/n_seq)  I(1/n_seq^2)  I(1/n_seq^3)  I(1/n_seq^4) \n##  5.663927e+05 -8.042330e+08  5.199467e+11 -1.184486e+14\ntibble(\n  n = n_seq, \n  Biais = bias, \n  lm1 = predict(lm1),\n  lm2 = predict(lm2), \n  lm4 = predict(lm4)\n) %>% \n  pivot_longer(cols = -n) %>% \n  ggplot() +\n    geom_line(aes(x = n, y = value, color = name, lty = name)) +\n    coord_cartesian(ylim = c(0, 250)) +\n    labs(\n      color = \"Nombre d'espèces\", \n      lty = \"Nombre d'espèces\",\n      y = \"Nombre d'espèces\"\n    )"},{"path":"chap-MesuresNeutres.html","id":"lestimateur-du-bootstrap","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.1.1.4 L’estimateur du bootstrap","text":"L’estimateur du bootstrap (E. P. Smith Belle 1984) est\n\\[\\begin{equation}\n  \\tag{3.22}\n  \\hat{S}_\\mathit{b} = {f_{>0}} + \\sum_s{(1 - p_s)^n}.\n\\end{equation}\\]Il est peu utilisé parce que le jackknife est plus performant (Colwell Coddington 1994).","code":""},{"path":"chap-MesuresNeutres.html","id":"calcul","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.1.1.5 Calcul","text":"Ces estimateurs peuvent être calculés de façon relativement simple à l’aide du logiciel SPADE, dans sa version pour R (Chao et al. 2016).\nLe guide de l’utilisateur présente quelques estimateurs supplémentaires et des directives pour choisir.\nIl est conseillé d’utiliser Chao1 pour une estimation minimale, et ACE pour une estimation moins biaisée de la richesse.Les intervalles de confiance de chaque estimateur sont calculés par bootstrap : même quand la variance d’un estimateur est connue, sa loi ne l’est généralement pas, et le calcul analytique de l’intervalle de confiance n’est pas possible.Les estimateurs et leurs intervalles de confiance peuvent également être calculés avec le package vegan qui dispose pour cela de deux fonctions : specpool et estimateR.specpool est basé sur les incidences des espèces dans un ensemble de sites d’observation et donne une estimation unique de la richesse selon les méthodes Chao2, jackknife (ordre 1 et 2) et bootstrap.\nL’écart-type de l’estimateur est également fourni par la fonction, sauf pour le jackknife d’ordre 2.estimateR est basé sur les abondances des espèces et retourne un estimateur de la richesse spécifique par site et non global comme specpool.","code":""},{"path":"chap-MesuresNeutres.html","id":"exemple","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.1.1.6 Exemple","text":"utilise les données de Barro Colorado Island (BCI).\nLa parcelle été divisée en carrés de 1 ha.\nLe tableau d’entrée est un dataframe contenant, pour chaque espèce d’arbres (\\(\\mathit{DBH}\\ge\\) 10 cm), ses effectifs par carré.charge le tableau de données :utilise la fonction estimateR pour calculer la richesse des deux premiers carrés :Le package SPECIES (Wang 2011) permet de calculer les estimateurs jackknife d’ordre supérieur à 2 et surtout choisit l’ordre qui fournit le meilleur compromis entre biais et variance.Comparaison des fonctions sur l’ensemble du dispositif BCI (\\(f_{>0}=225\\), \\(f_1=19\\)) :Comparaison avec la valeur de l’équation (3.18) :La valeur du jackknife 1 fournie par specpool est fausse.\nLa fonction jackknife de SPECIES donne le bon résultat, avec un intervalle de confiance calculé en supposant que la distribution est normale (\\(\\pm\\) 1,96 écart-type au seuil de 95 %)L’estimateur du bootstrap est calculable simplement :","code":"\nlibrary(\"vegan\")\ndata(BCI)\nestimateR(BCI[1:2,])##                   1          2\n## S.obs     93.000000  84.000000\n## S.chao1  117.473684 117.214286\n## se.chao1  11.583785  15.918953\n## S.ACE    122.848959 117.317307\n## se.ACE     5.736054   5.571998\nspecpool(BCI)##     Species     chao chao.se  jack1 jack1.se    jack2\n## All     225 236.3732 6.54361 245.58 5.650522 247.8722\n##         boot  boot.se  n\n## All 235.6862 3.468888 50\nlibrary(\"SPECIES\")\n# Distribution du nombre d'espèces (vecteur: \n# noms = nombre d'individus\n# valeurs = nombres d'espèces ayant ce nombre d'individus)\nbci_abd <- colSums(BCI)\n# Mise au format requis (matrice:\n# colonne 1 = nombre d'individus\n# colonne 2 = nombres d'espèces ayant ce nombre d'individus)\n# par la fonction abd_freq_count dans divent\njackknife(as.matrix(abd_freq_count(bci_abd)))## \n## Your specified order is larger than that determined by the test, \n## Therefore the order from the test is used.## $JackknifeOrder\n## [1] 1\n## \n## $Nhat\n## [1] 244\n## \n## $SE\n## [1] 6.164414\n## \n## $CI\n##       lb  ub\n## [1,] 232 256\n# Nombre d'espèces par effectif observé\nbci_abd_freq_count <- tapply(bci_abd, bci_abd, length)\n# Calcul direct de Jack1\nsum(bci_abd_freq_count) + \n  bci_abd_freq_count[1] * (sum(bci_abd) - 1) / sum(bci_abd)##        1 \n## 243.9991\n# Effectif total\nbci_n <- sum(bci_abd)\n# Probabilités\nbci_prob <- bci_abd / bci_n\n# Estimateur du bootstrap\nlength(bci_prob) + sum((1 - bci_prob)^bci_n)## [1] 234.3517"},{"path":"chap-MesuresNeutres.html","id":"sec-ChoixEstimateur","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.1.1.7 Choix de l’estimateur","text":"Des tests empiriques poussés ont été menés par Brose, Martinez, Williams (2003) pour permettre le choix du meilleur estimateur de la richesse en fonction de la complétude de l’échantillonnage \\(f_{>0}/{S}\\).\nLes auteurs appellent cette proportion couverture (coverage).\nLe terme completeness été proposé par Beck Schwanghart (2010) pour éviter la confusion avec le taux de couverture défini par Good (vu en section 1.5).\nLa complétude est inférieure à la couverture : toutes les espèces ont le même poids alors que les espèces manquantes sont plus rares et pénalisent moins le taux de couverture.\nFigure 3.3: Arbre de décision du meilleur estimateur du nombre d’espèces.\nDans tous les cas, les estimateurs jackknife sont les meilleurs.\nL’arbre de décision est en figure 3.3 (Brose, Martinez, Williams 2003, fig. 6).\nLe choix dépend principalement de la complétude (coverage sur la figure).\nUne première estimation est nécessaire par plusieurs estimateurs.\nSi les résultats sont cohérents, choisir un estimateur jackknife d’ordre d’autant plus faible que la complétude est grande.\nAu-delà de 96%, le nombre d’espèces observé est plus performant parce que les jackknifes surestiment \\(S\\).\nS’ils sont incohérents (intervalle des estimations supérieur à 50 % de leur moyenne), le critère majeur est l’équitabilité (voir section ??).\nSi elle est faible (de l’ordre de 0,5 à 0,6), les estimateurs jackknife 2 à 4 sont performants, l’ordre diminuant avec l’intensité d’échantillonnage (forte : 10%, faible : 0,5 % de la communauté).\nPour une forte équitabilité (0,8 à 0,9), préférera jackknife 1 ou 2.Pour BCI, le nombre d’espèces estimé par jackknife 1 est 244.\nLa complétude est \\({225}/{244} = 92\\%\\), dans le domaine de validité du jackknife 1 (74 % à 96 %) qui est donc le bon estimateur.La parcelle 6 de Paracou nécessite l’estimateur jackknife 2 :Chiu et al. (2014), à partir d’autres simulations, préfèrent l’utilisation de l’estimateur iChao1.\nQuand l’échantillonnage est suffisant, les estimateurs de Chao ont l’avantage de posséder une base théorique solide et de fournir une borne inférieure du nombre d’espèces possible.\nDans ce cas, les estimations du jackknife d’ordre 1 sont cohérentes avec celles de Chao.\nEn revanche, quand l’échantillonnage est insuffisant, l’estimateur jackknife d’ordre supérieur à 1 permet de réduire le biais d’estimation, au prix d’une variance accrue (Marcon 2015).Enfin, Beguinot (2015, 2016) suggère d’utiliser en règle générale le jackknife 2 (mais ne traite pas les cas dans lesquels l’échantillonnage est trop faible pour justifier un ordre supérieur) tant que le nombre de singletons est supérieur à \\(2-\\sqrt(2) \\approx 0,6\\) fois le nombre de doubletons.\nLe ratio des singletons sur les doubletons diminue quand l’échantillonnage approche de l’exhaustivité.\nQuand le seuil de 0,6 est dépassé, la valeur de l’estimateur de Chao devient supérieur au jackknife 2 et doit être utilisé.\nCe seuil est cohérent avec les règles de Brose, Martinez, Williams (2003).","code":"\nlibrary(\"divent\")\ndiv_richness(colSums(paracou_6_abd))## # A tibble: 1 × 3\n##   estimator   order diversity\n##   <chr>       <dbl>     <dbl>\n## 1 Jackknife 2     0       473\n# Complétude\ndiv_richness(colSums(paracou_6_abd), estimator = \"naive\", as_numeric = TRUE) / \n  div_richness(colSums(paracou_6_abd), as_numeric = TRUE)## [1] 0.7082452"},{"path":"chap-MesuresNeutres.html","id":"sec-Extrapol","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.1.1.8 Prédiction de la richesse d’un nouvel échantillon","text":"La prédiction du nombre d’espèces \\(\\hat{S'}\\) découvert dans une nouvelle placette d’un habitat dans lequel déjà échantillonné est une question importante, par exemple pour évaluer le nombre d’espèces préservées dans le cadre d’une mise en réserve, ou évaluer le nombre d’espèces perdues en réduisant la surface d’une forêt.Shen, Chao, Lin (2003) proposent un estimateur et le confrontent avec succès à des estimateurs antérieurs.\nnote \\(\\hat{f_0}(n)\\) l’estimateur du nombre d’espèces non observées dans le premier échantillon, et \\(\\hat{C}\\) l’estimateur de son taux de couverture.\nL’estimateur du nombre d’espèces du nouvel échantillon de \\(n'\\) individus est\\[\\begin{equation}\n  \\hat{S'}\n  = \\hat{f_0}(n) \\left[\n    1 - {\\left( 1 - \\frac{1 - \\hat{C}}{\\hat{f_0}(n)} \\right)}^{n'}\n  \\right].\n\\end{equation}\\]\\(\\hat{f_0}(n)\\) est obtenu par la différence entre les nombres d’espèces estimé et observé : \\(\\hat{f_0}(n) = \\hat{S} - f_{>0}(n)\\).Exemple de BCI, suite : combien de nouvelles espèces seront découvertes en échantillonnant plus ?\nFigure 3.4: Nombre de nouvelles espèces découvertes en fonction de l’effort d’échantillonnage supplémentaire (données de BCI). Seulement 7 nouvelles espèces seront observées en échantillonnant 10000 arbres supplémentaires (environ 25 ha en plus des 50 ha de la parcelle qui contiennent 225 espèces).\nLe taux de couverture de l’inventaire de BCI est très proche de 100%, donc peu de nouvelles espèces seront découvertes en augmentant l’effort d’échantillonnage.\nLa courbe obtenue est en figure 3.4.Le code R nécessaire pour réaliser la figure est :La question de l’extrapolation de la richesse est traitée plus en détail dans les sections ?? et ??.","code":"\n# Espèces non observées\nbci_abd %>% \n  div_richness() %>% \n  pull(diversity) %>% \n  `-`(length(BCI_abd)) %>% \n  print() ->\n  bci_f_0## [1] 19\n# Taux de couverture\nbci_abd %>% \n  coverage %>% \n  pull(coverage) %>% \n  print -> \n  bci_C## [1] 0.9991146\n# Nouvelles espèces en fonction du nombre de nouveaux individus\nS_prime <- function(n_prime, f_0, C) {\n  f_0 * (1 - (1 - (1 - C) / f_0)^n_prime)\n}\n# Graphique\ntibble(x = 1:10000) %>% \n  ggplot(aes(x)) + \n  stat_function(\n    fun = S_prime, \n    args = list(f_0 = bci_f_0, C = bci_C)\n  ) +\n  labs(x = \"n'\", y = \"S'\")"},{"path":"chap-MesuresNeutres.html","id":"inférence-du-nombre-despèces-à-partir-de-la-sad","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.1.2 Inférence du nombre d’espèces à partir de la SAD","text":"","code":""},{"path":"chap-MesuresNeutres.html","id":"distribution-de-preston","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.1.2.1 Distribution de Preston","text":"Preston (1948) fournit dès l’introduction de son modèle log-normal une technique d’estimation du nombre total d’espèces par la célèbre méthode des octaves.\nElle est disponible dans le package vegan :L’ajustement direct du modèle aux données, sans regroupement par octaves (Williamson Gaston 2005), est également possible (figure 3.5) :\nFigure 3.5: Ajustement du modèle de Preston aux données de BCI.\nLe code R nécessaire pour réaliser la figure est :","code":"\nveiledspec(bci_abd)## Extrapolated     Observed       Veiled \n##    235.40577    225.00000     10.40577\nbci_preston <- prestondistr(bci_abd)\nveiledspec(bci_preston)## Extrapolated     Observed       Veiled \n##   230.931018   225.000000     5.931018\nplot(bci_preston)"},{"path":"chap-MesuresNeutres.html","id":"maximum-de-vraisemblance-dune-distribution-de-fisher","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.1.2.2 Maximum de vraisemblance d’une distribution de Fisher","text":"Norris Pollock (1998) supposent que la distribution des espèces suit le modèle de Fisher (voir chapitre ??) et infèrent le nombre d’espèces par maximum de vraisemblance non paramétrique (ils ne cherchent pas à inférer les paramètres de la loi de probabilité de \\(p_s\\) mais seulement à ajuster au mieux le modèle de Poisson aux valeurs de \\({\\hat{p}}_s\\) observées).Le calcul est possible avec la librairie SPECIES de R :Le problème de cette méthode d’estimation est qu’elle diverge fréquemment.\nLes calculs n’aboutissent pas si la queue de distribution n’est pas regroupée (il existe 108 valeurs différentes de \\(n_s\\) dans l’exemple de BCI : aucune des fonctions de SPECIES ne fonctionne en l’état).Wang et al. (2005) ont amélioré sa stabilité en pénalisant le calcul de la vraisemblance :Enfin, Wang (2010) perfectionne la technique d’estimation en supposant que les \\(p_s\\) suivent une loi gamma et en estimant aussi ses paramètres.\nLa souplesse de la loi gamma permet d’ajuster le modèle à des lois diverses et l’estimateur de Wang est très performant.Il est disponible dans SPECIES : fonction pcg.\nSon défaut est qu’il nécessite un très long temps de calcul (plusieurs heures selon les données).","code":"\n# Mise au format requis (matrice:\n# colonne 1 = nombre d'individus\n# colonne 2 = nombres d'espèces ayant ce nombre d'individus)\nbci_abd_freq_count <- as.matrix(abd_freq_count(bci_abd))\n# Regroupement de la queue de distribution: la longueur du vecteur est limitée à 25 pour alléger les calculs.\nbci_abd_freq_count[25, 2] <- sum(\n  bci_abd_freq_count[25:nrow(bci_abd_freq_count), 2]\n)\nbci_abd_freq_count <- bci_abd_freq_count[1:25, ]\nunpmle(bci_abd_freq_count)## Method: Unconditional NPMLE method by Norris and Pollock 1996, 1998, \n##         using algorithm by Wang and Lindsay 2005: \n## \n##         MLE=                                239 \n##         Estimated Poisson mixture components:       \n##         p=                                  1.10372 3.595437 10.60832 \n##         pi=                                 0.402579 0.2525368 0.3448842## $Nhat\n## [1] 239\npnpmle(bci_abd_freq_count)## Method: Penalized NPMLE method by  Wang and Lindsay 2005. \n## \n##         MLE=                                243 \n##         Estimated zero-truncated Poisson mixture components:       \n##         p=                                  0.9033625 3.397048 10.59029 \n##         pi=                                 0.2771211 0.3208847 0.4019942## $Nhat\n## [1] 243\n# Calcul long\npcg(bci_abd_freq_count)"},{"path":"chap-MesuresNeutres.html","id":"sec-RichesseSAC","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.1.3 Inférence du nombre d’espèces à partir de courbes d’accumulation","text":"Cette approche consiste à extrapoler la courbe d’accumulation observée.Le modèle le plus connu est celui de Michaelis-Menten (Michaelis Menten 1913) proposé par Clench (1979).\nEn fonction de l’effort d’échantillonnage \\(n\\), évalué en temps (il s’agit de la collecte de papillons), le nombre d’espèces découvert augmente jusqu’à une asymptote égale au nombre d’espèces total :\\[\\begin{equation}\n  S(n) = S\\frac{n}{K + n}.\n\\end{equation}\\]\\(K\\) est une constante, que Clench relie à la difficulté de collecte.L’estimation empirique du modèle de Michaelis-Menten peut être faite avec R3.\nLes 50 carrés de BCI sont utilisés pour fabriquer une courbe d’accumulation :Le modèle est ajusté par nlsfit.\nDes valeurs de départ doivent être fournies pour \\(K\\) et \\(\\hat{S}\\).\n\\(K\\) est la valeur de \\(n\\) correspondant à \\(\\hat{S}^{n} = \\hat{S} / 2\\).\nUne approximation suffisante est \\(n / 4\\).\nPour \\(\\hat{S}\\), le nombre total d’espèces inventoriées est un bon choix.\nLe résultat se trouve en figure 3.7.L’estimation précédente utilise la méthode des moindres carrés, qui suppose l’indépendance des résidus, hypothèses évidemment violée par une courbe d’accumulation (Colwell Coddington 1994).\nL’estimation par le maximum de vraisemblance est plus convenable (Raaijmakers 1987).\nElle utilise la totalité des points de la courbe d’accumulation.\nLa courbe d’accumulation de BCI est présentée en figure ??.\nSes données sont utilisées ici :L’estimation précédente repose sur une approximation numérique.\nLe paramètre \\(K\\) peut être estimé plus précisément par résolution numérique de l’équation exacte du maximum de vraisemblance :Le nombre d’espèces estimé est 224, inférieur au nombre d’espèces observé.Pour calculer l’intervalle de confiance, il est plus simple de passer par une transformation linéaire du modèle (Lineweaver Burk 1934) :\\[\\begin{equation}\n  \\tag{3.23}\n  \\left [\\frac{1}{\\hat{S}(n)} \\right]\n  = \\frac{K}{\\hat{S}} \\left[ \\frac{1}{n} \\right] + \\frac{1}{\\hat{S}}\n\\end{equation}\\]Le nombre d’espèces est estimé par l’inverse de l’ordonnée à l’origine du modèle.\nFigure 3.6: Ajustement du même modèle de Michaelis-Menten transformé selon Lineweaver et Burk.\nvoit assez clairement que le modèle (figure 3.6) s’ajuste mal quand il est représenté sous cette forme (Raaijmakers 1987).Le code R nécessaire pour réaliser la figure est :Le nombre d’espèces estimé est inférieur au nombre observé, qui ne se trouve même pas dans l’intervalle de confiance à 95%.\nLe modèle de Michaelis-Menten ne convient pas.Soberón M. Llorente B. (1993) développent un cadre théorique plus vaste qui permet d’ajuster la courbe d’accumulation à plusieurs modèles.\nCes modèles sont efficaces empiriquement mais manquent de support théorique pour justifier leur forme.\nLe modèle le plus simple est exponentiel négatif.\nSi la probabilité de trouver une nouvelle espèce est proportionnelle au nombre d’espèces non encore découvertes, la courbe d’accumulation suit la relation\\[\\begin{equation}\n  \\tag{3.24}\n  S() = S \\left( 1 - e^{kn} \\right).\n\\end{equation}\\]Les paramètres peuvent être estimés par la méthode des moindres carrés :Ce modèle, proposé par Holdridge et al. (1971), sous-estime la richesse parce que la probabilité de découvrir une nouvelle espèce diminue plus vite que le nombre d’espèces restant à découvrir : les dernières espèces sont plus rares et donc plus difficiles à détecter.Un modèle plus réaliste définit cette probabilité comme une fonction décroissante du nombre d’espèces manquantes.\nLa fonction la plus simple est une exponentielle négative mais elle ne s’annule jamais et le nombre d’espèces n’pas d’asymptote.\nUn paramètre supplémentaire pour obtenir l’asymptote est nécessaire et aboutir à la relation\\[\\begin{equation}\n  \\tag{3.25}\n  f = \\frac{1}{z} \\ln \\left[ \\frac{}{c} - \\frac{-c}{c} e^{-czn} \\right].\n\\end{equation}\\]Les paramètres à estimer sont \\(z\\), \\(\\) et \\(c\\).\nFigure 3.7: Ajustement des modèles de Michaelis-Menten et de de Soberón et Llorente (modèle exponentiel négatif et modèle à trois paramètres) aux données de BCI. Les points représentent le nombre d’espèces cumulées en fonction du nombre d’arbres. Le modèle exponentiel négatif (Holdridge) sous-estime la richesse, plus que celui de Michaelis-Menten (Clench). Le modèle à trois paramètres s’ajuste mieux aux données, mais il surestime probablement la richesse.\nL’estimation est cette fois supérieure à celle du jackknife (244 espèces).La figure 3.7 présente les deux ajustements de modèle de Soberón et Llorente avec celui de Clench.\nL’estimation de la richesse par extrapolation est plus incertaine que par les méthodes non paramétriques.\nElle est très peu utilisée.Le code R nécessaire pour réaliser la figure est :","code":"\n# Cumul de l'inventaire\n# Nombre d'arbres par espèce, cumulé par carré\nbci_cumul_n_s <- apply(BCI, 2, cumsum)\n# Nombre d'arbres cumulé par carré\nbci_cumul_n <- cumsum(rowSums(BCI))\n# Nombre total d'arbres\nbci_n <- sum(BCI)\n# Nombre d'espèces cumulées par carré\nbci_cumul_S <- apply(bci_cumul_n_s, 1, function(x) sum(x>0))\n# Ajustement du modèle\n(nlsfit <- nls(\n  bci_cumul_S ~ S * bci_cumul_n / (K + bci_cumul_n), \n  data = list(bci_cumul_n, bci_cumul_S), \n  start = list(K = max(bci_cumul_n) / 4, S = max(bci_cumul_S))\n))## Nonlinear regression model\n##   model: bci_cumul_S ~ S * bci_cumul_n/(K + bci_cumul_n)\n##    data: list(bci_cumul_n, bci_cumul_S)\n##      K      S \n## 1251.0  232.8 \n##  residual sum-of-squares: 3066\n## \n## Number of iterations to convergence: 6 \n## Achieved convergence tolerance: 7.861e-06\nbci_sac <- specaccum(BCI, \"random\")\n# Calculs intermédiaires\ny_i <- bci_sac$richness\nn <- length(y_i)\nx_i <- y_i / (1:n)\nx_bar <- mean(x_i)\ny_bar <- mean(y_i)\nS_yy <- sum((y_i - y_bar)^2)\nS_xx <- sum((x_i - x_bar)^2)\nS_xy <- sum((x_i - x_bar) * (y_i - y_bar))\n# Estimations\n(K_hat <- (x_bar * S_yy - y_bar * S_xy) / (y_bar * S_xx - x_bar * S_xy))## [1] 1.704586\n(S_hat <- y_bar + K_hat * x_bar)## [1] 223.5082\n# Equation que K_hat doit annuler\nf <- function(K_hat) {\n  S_xy + \n    K_hat * S_xx - \n    (S_yy + 2 * K_hat * S_xy + K_hat^2 * S_xx) * sum(x_i / (y_i + K_hat * x_i) / n)\n}\n# Résolution numérique, l'intervalle de recherche doit être fourni\nsolution <- uniroot(f, c(0, 1E+7))\n(K_hat <- solution$root)## [1] 1.7046\n(S_hat <- y_bar + K_hat * x_bar)## [1] 223.5084\ny <- 1 / bci_cumul_S\nx <- 1 / bci_cumul_n\nlm1 <- lm(y ~ x)\n(S <- 1/lm1$coef[1])## (Intercept) \n##     217.002\ntibble(x, y) %>% \n  ggplot(aes(x, y)) + \n    geom_point() +\n    stat_smooth(method = \"lm\", col = \"red\") +\n    labs(x = \"1/n\", y=\"1/S\")\n(nlsexp <- nls(\n  bci_cumul_S ~ S * (1 - exp(k * bci_cumul_n)), \n  data = list(bci_cumul_n, bci_cumul_S), \n  start = list(S = max(bci_cumul_S), k = -1 / 1000)\n))## Nonlinear regression model\n##   model: bci_cumul_S ~ S * (1 - exp(k * bci_cumul_n))\n##    data: list(bci_cumul_n, bci_cumul_S)\n##          S          k \n## 212.198081  -0.000494 \n##  residual sum-of-squares: 10664\n## \n## Number of iterations to convergence: 13 \n## Achieved convergence tolerance: 8.047e-06\n(nlslog <- nls(\n  bci_cumul_S ~ 1 / z * log(a / c - (a - c) / c * exp(-c * z * bci_cumul_n)), \n  data = list(bci_cumul_n, bci_cumul_S), \n  start = list(z = .05, a = 1, c = .001)\n))## Nonlinear regression model\n##   model: bci_cumul_S ~ 1/z * log(a/c - (a - c)/c * exp(-c * z * bci_cumul_n))\n##    data: list(bci_cumul_n, bci_cumul_S)\n##        z        a        c \n## 0.025139 0.755365 0.001114 \n##  residual sum-of-squares: 446.1\n## \n## Number of iterations to convergence: 4 \n## Achieved convergence tolerance: 4.366e-06\n# Nombre d'espèces\ncoefs <- coef(nlslog)\nlog(coefs[\"a\"] / coefs[\"c\"]) / coefs[\"z\"]##        a \n## 259.3128\nx <- seq(from = 0, to = max(bci_cumul_n), length = 255)\nx_new <- list(bci_cumul_n = x)\ntibble(\n  x, \n  `Michaelis-Menten` = predict(nlsfit, newdata = x_new),\n  `Exponentiel` = predict(nlsexp, newdata = x_new),\n  `Trois paramètres` = predict(nlslog, newdata = x_new)\n) %>% \n  pivot_longer(cols = -x) %>% \n  ggplot() +\n    geom_line(aes(x = x, y = value, lty = name)) +\n    geom_point(aes(bci_cumul_n, bci_cumul_S), data.frame(bci_cumul_n, bci_cumul_S)) +\n    labs(\n      x = \"Nombre d'arbres\", \n      y = \"Nombre d'espèces\", \n      lty = \"Modèle\"\n    )"},{"path":"chap-MesuresNeutres.html","id":"diversité-générique","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.1.4 Diversité générique","text":"La détermination des genres est plus facile et fiable que celle des espèces, le biais d’échantillonnage moins sensible (le nombre de singletons diminue rapidement en regroupant les données), et les coûts d’inventaire sont généralement largement réduits (Balmford, Jayasuriya, Green 1996).\nLe choix d’estimer la diversité de taxons de rang supérieur (genres ou même familles au lieu des espèces) est envisageable (Williams Gaston 1994).Empiriquement, la corrélation entre la richesse générique et la richesse spécifique (des angiospermes, des oiseaux et des mammifères) est bonne en forêt tropicale (Balmford, Green, Murray 1996), suffisante pour comparer les communautés, même si la prédiction de la richesse spécifique à partir de la richesse générique est très imprécise.Cartozo et al. (2008) ont montré que le nombre de taxons de niveau supérieur (genre par rapport aux espèces, ordres par rapport aux sous-ordres) est universellement proportionnel au nombre de taxons du niveau immédiatement inférieur à la puissance 0,61. Cette relation est validée à l’échelle mondiale pour les systèmes végétaux. La loi de puissance reste valide pour des assemblages aléatoires, c’est donc la conséquence de propriétés mathématiques (Caldarelli et al. 2002), mais la puissance de la relation est plus élevée (les communautés réelles sont plus agrégées du point de vue phylogénétique que sous l’hypothèse nulle d’un assemblage aléatoire) et varie entre les niveaux.","code":""},{"path":"chap-MesuresNeutres.html","id":"combien-y-a-t-il-despèces-différentes-sur-terre","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.1.5 Combien y a-t-il d’espèces différentes sur Terre ?","text":"La question de l’estimation du nombre total d’espèces génère une abondante littérature.\nMora et al. (2011) en font une revue et proposent une méthode nouvelle.Dans chaque règne, le nombre de taxons de niveaux supérieurs (phylums, classes, ordres, familles et même genres) est estimé par des modèles prolongeant jusqu’à leur asymptote les valeurs connues en fonction du temps.\nCette méthode est applicable jusqu’au niveau du genre (figure ??, à E).\nLe nombre de taxon de chaque niveau est lié à celui du niveau précédent, ce qui est représenté par la figure ??, G (Mora et al. 2011, fig. 1) sous la forme du relation linéaire entre le logarithme du logarithme du nombre de taxons et le rang (1 pour les phylums, 5 pour les genres).\nLa droite est prolongée jusqu’au rang 6 pour obtenir le nombre d’espèces.\nUne façon alternative de décrire la méthode est de dire que le nombre de taxons du niveau \\(n+1\\) est égal à celui du niveau \\(n\\) à la puissance \\(k\\).\nLa pente de la droite de la figure est \\(\\ln{k}\\).\nAucune justification de ce résultat majeur n’est donnée par les auteurs, si ce n’est leur vérification empirique.Le nombre total d’espèces estimé est 8,7 millions, tous règnes confondus, dans la fourchette des estimations précédentes (de 3 à 100 millions), et nécessitant près de 500 ans d’inventaires au rythme actuel des découvertes (May 2011).En se limitant aux arbres, l’estimation se monte à 16000 espèces pour l’Amazonie (ter Steege et al. 2013), de l’ordre de 5000 pour l’Afrique et entre 40000 et 53000 pour l’ensemble des tropiques (Slik et al. 2015) (donc pour l’ensemble de la planète, le nombre d’espèces non-tropicales étant négligeable).\nCes estimations sont obtenues par extrapolation du modèle en log-séries (chapitre ??) et sont sujettes au paradoxe de Fisher : les espèces représentées par un très petit nombre d’individu dans le modèle, notamment les singletons, sont les plus nombreuses.\nUne discussion approfondie est donnée par Stephen P. Hubbell (2015) : les espèces récemment apparues au sens du modèle ne sont pas détectables avant plusieurs générations, créant un décalage entre le nombre d’espèces reconnues par la taxonomie et le modèle.J. B. Wilson et al. (2012) compilent les relevés du nombre d’espèces de plantes vasculaires en fonction de la surface et retiennent uniquement les plus riches à chaque échelle spatiale (du millimètre carré à l’hectare).\nCes relevés sont tous situés en forêt tropicale ou en prairie tempérée gérée (les perturbations régulières et modérées y favorisent la diversité, conformément à la théorie de la perturbation intermédiaire (Connell 1978)).\nLa relation entre le nombre d’espèces et la surface est celle d’Arrhenius.\nSon extrapolation à la surface terrestre donne environ 220000 espèces, comparables à l’estimation de 275000 espèces rapportée par Mora et al.","code":""},{"path":"chap-MesuresNeutres.html","id":"indice-de-simpson","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.2 Indice de Simpson","text":"","code":""},{"path":"chap-MesuresNeutres.html","id":"définition","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.2.1 Définition","text":"note \\(p_s\\) la probabilité qu’un individu tiré au hasard appartienne à l’espèce \\(s\\).\nL’indice de Simpson (1949), ou Gini-Simpson, est\\[\\begin{equation}\n  \\tag{3.26}\n  E = 1 - \\sum^{S}_{s=1}{p^2_s}.\n\\end{equation}\\]Il peut être interprété comme la probabilité que deux individus tirés au hasard soient d’espèces différentes.\nIl est compris dans l’intervalle \\(\\left[ 0 ; 1 \\right[\\).\nSa valeur diminue avec la régularité de la distribution : \\(E=0\\) si une seule espèce une probabilité de 1, \\(E = 1 - 1 / S\\) si les \\(S\\) espèces ont la même probabilité \\(p_s = 1 / S\\).\nLa valeur 1 est atteinte pour un nombre infini d’espèces, de probabilités nulles.Deux autres formes de l’indice sont utilisées.\nTout d’abord, la probabilité que deux individus soient de la même espèce, souvent appelée indice de concentration de Simpson, qui est celui défini dans l’article original de Simpson :\\[\\begin{equation}\n  \\tag{3.27}\n  D = \\sum^{S}_{s=1}{p^2_s}.\n\\end{equation}\\]L’indice de Simpson est parfois considéré comme une mesure d’équitabilité (Olszewski 2004) mais il varie avec la richesse : cette approche est donc erronée.\nHurlbert (1971) l’divisé par sa valeur maximale \\(1 - 1 / S\\) pour obtenir une mesure d’équitabilité valide généralisée plus tard par Mendes et al. (2008), voir section ??.\nLe nombre d’espèces doit être estimé par les méthodes présentées plus haut, pour ne pas dépendre de la taille de l’échantillon.L’estimateur du maximum de vraisemblance de l’indice est\\[\\begin{equation}\n  \\tag{3.28}\n  \\hat{E} = 1 - \\sum^{f_{>0}}_{s=1}{\\hat{p}^2_s}.\n\\end{equation}\\]Le calcul de l’indice de Simpson peut se faire avec la fonction diversity disponible dans le package vegan de R ou avec la fonction ent_simpson du package divent, qui peut traiter plusieurs sites en même temps :Un historique de la définition de l’indice, de Gini (1912) à Simpson, inspiré par Turing, est fourni par Ellerman (2013).","code":"\nparacou_6_abd %>% \n  # Transformation des abondances en probabilités\n  as_probabilities() %>% \n  ent_simpson()## # A tibble: 4 × 5\n##   site      weight estimator order entropy\n##   <chr>      <dbl> <chr>     <dbl>   <dbl>\n## 1 subplot_1   1.56 naive         2   0.975\n## 2 subplot_2   1.56 naive         2   0.976\n## 3 subplot_3   1.56 naive         2   0.978\n## 4 subplot_4   1.56 naive         2   0.971"},{"path":"chap-MesuresNeutres.html","id":"estimation","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.2.2 Estimation","text":"Définissons l’indicatrice \\({{\\mathbf 1}}_{sh}\\) valant 1 si l’individu \\(h\\) appartient à l’espèce \\(s\\), 0 sinon.\n\\({{\\mathbf 1}}_{sh}\\) suit une loi de Bernoulli d’espérance \\(p_s\\) et de variance \\(p_s \\left( 1 - p_s \\right)\\).\n\\(E\\) est la somme sur toutes les espèces de cette variance.\nUn estimateur non biaisé d’une variance à partir d’un échantillon est la somme des écarts quadratiques divisée par le nombre d’observation moins une.\nL’estimateur \\(\\hat{E}\\) est légèrement biaisé parce qu’il est calculé à partir des \\({\\hat{p}}_s\\), ce qui revient à diviser la somme des écarts par \\(n\\), et non \\(n-1\\).\nUn estimateur non biaisé est (Good 1953; Lande 1996)\\[\\begin{equation}\n  \\tag{3.29}\n  \\tilde{E}\n  = \\left( \\frac{n}{n-1} \\right) \\left( 1 - \\sum^{f_{>0}}_{s=1}{{\\hat{p}}^2_s} \\right).\n\\end{equation}\\]La correction par \\(n / (n - 1)\\) tend rapidement vers 1 quand la taille de l’échantillon augmente : l’estimateur est très peu biaisé.Le non-échantillonnage des espèces rares est pris en compte dans cette correction parce qu’elle considère que \\(\\tilde{E}\\) est l’estimateur de variance d’un échantillon et non d’une population complètement connue.\nIl est négligeable : si \\(p_s\\) est petit, \\(p^2_s\\) est négligeable dans la somme.Simpson fourni un estimateur non biaisé de \\(D\\), à partir du calcul du nombre de paires d’individus tirés sans remise :\\[\\begin{equation}\n  \\tag{3.30}\n  \\tilde{D}\n  = \\frac{\\sum^{S}_{s=1}{n_s \\left( n_s - 1 \\right)}}{n \\left( n - 1 \\right)}.\n\\end{equation}\\]L’argumentation est totalement différente, mais le résultat est le même : \\(\\tilde{E}=1-\\tilde{D}\\).La fonction ent_simpson de divent accepte comme argument un vecteur d’abondances ou un dataframe contenant les données et propose par défaut la correction de Lande :","code":"\nparacou_6_abd %>% \n  ent_simpson()## # A tibble: 4 × 5\n##   site      weight estimator order entropy\n##   <chr>      <dbl> <chr>     <dbl>   <dbl>\n## 1 subplot_1   1.56 Lande         2   0.976\n## 2 subplot_2   1.56 Lande         2   0.978\n## 3 subplot_3   1.56 Lande         2   0.980\n## 4 subplot_4   1.56 Lande         2   0.972"},{"path":"chap-MesuresNeutres.html","id":"indice-de-shannon","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.3 Indice de Shannon","text":"","code":""},{"path":"chap-MesuresNeutres.html","id":"définition-1","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.3.1 Définition","text":"L’indice de Shannon (Shannon 1948; Shannon Weaver 1963), aussi appelé indice de Shannon-Weaver ou Shannon-Wiener (Spellerberg Feder 2003), ou simplement entropie est dérivé de la théorie de l’information :\\[\\begin{equation}\n  \\tag{3.31}\n  H = -\\sum^S_{s=1}{p_s\\ln{p_s}}.\n\\end{equation}\\]Considérons une placette forestière contenant \\(S\\) espèces végétales différentes.\nLa probabilité qu’une plante choisie au hasard appartienne à l’espèce \\(s\\) est notée \\(p_s\\).\nprélève \\(n\\) plantes, et enregistre la liste ordonnée des espèces des \\(n\\) plantes.\nSi \\(n\\) est suffisamment grand, le nombre de plantes de l’espèce \\(s\\) est \\(np_s\\).\nnote \\(L\\) le nombre de listes respectant ces conditions :\\[\\begin{equation}\n  \\tag{3.32}\n  L = \\frac{n!}{\\prod^S_{=1}{\\left( {np}_s \\right)!}}.\n\\end{equation}\\]Ce résultat est obtenu en calculant le nombre de positions possibles dans la liste pour les individus de la première espèce : \\(\\binom{n}{np_1}\\).\nLe nombre de positions pour la deuxième espèce est \\(\\binom{n-np_1}{np_2}\\).\nPour la \\(S\\)-ième espèce, le nombre est \\(\\binom{n-np_1-\\dots -np_{s-1}}{np_i}\\).\nLes produits de combinaisons se simplifient pour donner l’équation (3.32).peut maintenant écrire le logarithme de \\(L\\):\n\\[\\ln{L} = \\ln{n!} - \\sum^S_{s=1}{\\ln{np_s}!}.\\]\nutilise l’approximation de Stirling,\n\\[\\ln{n!} \\approx n \\ln{n} - n,\\]\npour obtenir après simplifications :\\[\\begin{equation}\n  \\tag{3.33}\n  \\ln{L} = -n \\sum^S_{s=1}{p_s \\ln{p_s}}.\n\\end{equation}\\]\\(H = (\\ln{L}) / n\\) est l’indice de Shannon.\nCe résultat est connu sous le nom de formule de Brillouin (1962).\nÀ l’origine, Shannon utilisé un logarithme de base 2 pour que \\(H\\) soit le nombre moyen de questions binaires (réponse oui ou non) nécessaire pour identifier l’espèce d’une plante (un caractère utilisé dans une chaîne dans le contexte du travail de Shannon).\nLes logarithmes naturels, de base 2 ou 10 ont été utilisés par la suite (Pielou 1966b).La formule (3.33) est celle de l’indice de Theil (1967), présenté en détail par Conceição Ferreira (2000), à l’origine utilisé pour mesurer les inégalités de revenu puis pour caractériser les structures spatiales en économie.\nL’indice est proportionnel au nombre de plantes choisies, peut donc le diviser par \\(n\\) et obtient l’indice de biodiversité de Shannon.\nCes indices ont été définis en choisissant des lettres au hasard pour former des chaînes de caractères.\nLeur valeur est le nombre de chaînes de caractères différentes que l’peut obtenir avec l’ensemble des lettres disponibles, c’est-à-dire la quantité d’information contenue dans l’ensemble des lettres.\nL’indice de Shannon donne une mesure de la biodiversité en tant que quantité d’information.L’estimateur du maximum de vraisemblance de l’indice est\\[\\begin{equation}\n  \\tag{3.34}\n  \\hat{H} = -\\sum^{f_{>0}}_{s=1}{\\hat{p}_s \\ln{\\hat{p}_s}}.\n\\end{equation}\\]Le calcul de l’indice de Shannon peut se faire avec la fonction diversity disponible dans le package vegan de R ou avec la fonction ent_shannon de divent :La distribution de l’estimateur est connue (Hutcheson 1970) mais elle est inutile en pratique à cause du biais d’estimation.Bulmer (1974) établit une relation entre l’indice de Shannon et l’indice \\(\\alpha\\) de Fisher, à condition que la distribution de l’abondance des espèces soit log-normale :\\[\\begin{equation}\n  \\tag{3.35}\n  \\hat{H}\n  = \\mathrm{\\Psi} \\left( \\hat{\\alpha} + 1 \\right) - \\mathrm{\\Psi} \\left( 1 \\right).\n\\end{equation}\\]\\(\\mathrm{\\Psi}(\\cdot)\\) est la fonction digamma, et \\(\\hat{\\alpha}\\) est l’estimateur de l’indice de Fisher (??) :La sous-estimation est assez sévère sur cet exemple.","code":"\nbci_abd %>% \n  as_probabilities() %>% \n  ent_shannon()## # A tibble: 1 × 5\n##   site           weight estimator order entropy\n##   <chr>           <dbl> <chr>     <dbl>   <dbl>\n## 1 site_707269321      1 naive         1    4.27\ndigamma(fisher.alpha(colSums(BCI)) + 1) - digamma(1)## [1] 4.148322"},{"path":"chap-MesuresNeutres.html","id":"sec-BiaisShannon","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.3.2 Estimation","text":"Basharin (1959) montré que l’estimateur de l’indice de Shannon était biaisé parce que des espèces ne sont pas échantillonnées.\nSi \\(S\\) est le nombre d’espèces réel et \\(n\\) le nombre d’individus échantillonnés, le biais est\\[\\begin{equation}\n  \\tag{3.36}\n  \\mathbb{E}\\left( \\hat{H} \\right) - H\n  = -\\frac{S - 1}{2n} + O\\left(n^{-2}\\right).\n\\end{equation}\\]\\(O(n^{-2})\\) est un terme négligeable.\nLa valeur estimée à partir des données est donc trop faible, d’autant plus que le nombre d’espèces total est grand mais d’autant moins que l’échantillonnage est important.\nComme le nombre d’espèces \\(S\\) n’est pas observable, le biais réel est inconnu.L’estimateur de Miller-Madow (Miller 1955) utilise l’information disponible, en sous-estimant le nombre d’espèces et donc l’entropie :\n\\[\\begin{equation}\n  \\tag{3.37}\n  \\tilde{H} = -\\sum^{f_{>0}}_{s=1}{\\hat{p}_s \\ln{\\hat{p}_s}} + \\frac{f_{>0} - 1}{2n}.\n\\end{equation}\\]Chao Shen (2003) établissent un estimateur moins biaisé à partir du taux de couverture de l’échantillonnage \\(\\hat{C}\\):\\[\\begin{equation}\n  \\tag{3.38}\n  \\tilde{H}\n  = -\\sum_{s=1}^{f_{>0}}{\\frac\n    {\\hat{C} \\hat{p}_s \\ln\\left( \\hat{C} \\hat{p}_s \\right)}\n    {1 - \\left( 1 - \\hat{C}\\hat{p}_s \\right)^n}}.\n\\end{equation}\\]Multiplier les fréquences observées par le taux de couverture permet d’obtenir un estimateur non biaisé des probabilités conditionnellement aux espèces non observées (Ashbridge Goudie 2000).Le terme au dénominateur est la correction de Horvitz Thompson (1952) : chaque terme de la somme est divisé par la probabilité d’observer au moins une fois l’espèce correspondante.\nIl tend vers 1 quand la taille de l’échantillon augmente.Beck Schwanghart (2010) montrent que la correction du biais est efficace, même à des niveaux de complétude de l’échantillonnage (voir section 3.1.1.7) très faibles. Vu, Yu, Kass (2007) étudient la vitesse de convergence de l’estimateur.Z. Zhang (2012) définit l’indice de Simpson généralisé :\\[\\begin{equation}\n  \\tag{3.39}\n  \\zeta_{u,v} = \\sum^S_{s=1}{p^u_s{\\left( 1 - p_s \\right)}^v},\n\\end{equation}\\]où \\(\\zeta_{u,v}\\) est la somme sur toutes les espèces de la probabilité de rencontrer \\(u\\) fois l’espèce dans un échantillon de taille \\(u+v\\).\nL’indice de Shannon peut s’exprimer en fonction de \\(\\zeta_{1,v}\\):\\[\\begin{equation}\n  \\tag{3.40}\n  H = \\sum^{\\infty}_{v=1}{\\frac{1}{v} \\zeta_{1,v}}.\n\\end{equation}\\]Les premiers termes de la somme, jusqu’à \\(v=n-1\\) peuvent être estimés à partir des données, les suivants constituent le biais de l’estimateur, qui est calculé en pratique par\\[\\begin{equation}\n  \\tag{3.41}\n  H_z\n  = \\sum^{n-1}_{v=1}{\\frac{1}{v}\\left\\{\n    \\frac{n^{v+1}\\left[ n - \\left(v + 1 \\right) \\right]!}{n!}\n    \\sum^{f_{>0}}_{s=1}{p_s \\prod^{v-1}_{j=0}{\n      \\left( 1 - \\hat{p}_s - \\frac{j}{n} \\right)}\n    }\n  \\right\\}}.\n\\end{equation}\\]Z. Zhang (2013) montre que le biais de l’estimateur \\(H_z\\) est asymptotiquement normal et calcule sa variance.\nZ. Zhang Grabchak (2013) améliorent l’estimateur en le complétant par un estimateur de son biais, mais les calculs deviennent excessivement complexes.\nVinck et al. (2012) appliquent la même démarche avec un estimateur bayésien du biais, utilisant un prior aussi plat que possible pour la valeur de l’entropie (et non un prior plat sur les probabilités, qui tire l’estimateur vers l’entropie maximale).\nCet estimateur nécessite de connaître le nombre d’espèces, ce qui empêche son utilisation sur des données d’écologie.Pielou (1966a) développé une autre méthode de correction de biais lorsque de nombreux relevés de petite taille sont disponibles.\n\\(\\ln{L}\\) est calculé pour un relevé choisi aléatoirement puis les données du premier relevé sont ajoutées à celles d’un autre, puis un autre jusqu’à ce que \\(H=(\\ln{L}) / n\\) n’augmente plus : la diversité augmente dans un premier temps mais se stabilise quand l’effet des espèces ajoutées est compensé par celui de la diminution de l’équitabilité due aux espèces présentes dans tous les relevés.\nÀ partir de ce seuil, l’augmentation de \\(\\ln{L}\\) par individu ajouté est calculée pour chaque relevé supplémentaire.\nSon espérance, estimée par sa moyenne calculée en ajoutant tous les relevés disponibles, est \\(\\tilde{H}\\).Chao, Wang, Jost (2013) utilisent l’estimateur de la pente de la courbe de raréfaction, calculé précédemment (Chao Jost 2012) pour estimer la richesse spécifique, pour fournir un estimateur extrêmement performant :\\[\\begin{align}\n  \\tag{3.42}\n  \\tilde{H}\n  = &-\\sum_{s=1}^{f_{>0}}\n    {\\frac{n_s}{n} \\left( \\mathrm{\\Psi}\\left( n \\right) - \\mathrm{\\Psi}\\left( n_s \\right) \\right)} \\\\\n    &-\\frac{s_{1}}{n} {\\left(1 - \\right)}^{1 - n} \\left(\n      -\\ln\\left( \\right) -\\sum^{n-1}_{r=1}{\\frac{1}{r}{\\left( 1 - \\right)}^r} \\right\n    ),\n\\end{align}\\]où \\(\\mathrm{\\Psi}(\\cdot)\\) est la fonction digamma et \\(\\) vaut :\\(2s_{2} / [(n - 1) s_{1} + 2 s_{2}]\\) en présence de singletons et doubletons ;\\(2 / [(n - 1) (s_1 -1) + 2]\\) en présence de singletons seulement ;\\(1\\) en absence de singletons et doubletons.Enfin, la littérature de physique statistique s’est abondamment intéressée à cette question (Bonachela, Hinrichsen, Muñoz (2008) en font une revue).\nLe problème traité est la non-linéarité de l’indice de Shannon par rapport aux probabilités qui entraîne un biais d’estimation.\nLa fonction logarithme fournit un exemple simple : l’espérance de \\(\\ln(p_s)\\) n’est pas le logarithme de l’espérance de \\(p_s\\) parce que la fonction \\(\\ln\\) est concave.\nChaque estimateur \\({\\hat{p}}_s\\) fluctue autour de \\(p_s\\) mais vaut \\(p_s\\) en moyenne.\nÀ cause de la concavité, \\(\\ln(\\hat{p}_s)\\) est en moyenne inférieur à \\(\\ln(p_s)\\): cette relation est connue sous le nom d’inégalité de Jensen (1906).\nL’indice de Shannon est concave (figure 3.8) donc son estimateur (3.31) est biaisé négativement, même sans prendre en considération les espèces non observées.\nFigure 3.8: Courbe de \\(x\\ln x\\) entre 0 et 1.\nCode de la figure 3.8 :Le biais peut être évalué par simulation : 10000 tirages sont réalisés dans une loi normale d’espérance \\(p_s\\) choisie et d’écart-type 0.01.\nLe biais est la différence entre \\(-p_s \\ln{p_s}\\) (connu) et la moyenne des 1000 valeurs de \\(-\\hat{p}_s \\ln{\\hat{p}}_s\\) (la probabilité est estimée par sa réalisation à chaque tirage).\nLa valeur du biais en fonction de \\(p_s\\) est en figure 3.9.\nLe biais de l’indice de Shannon est la somme des biais pour toutes les probabilités spécifiques de la communauté étudiée, et son calcul est toujours l’objet de recherches.\nFigure 3.9: Biais de \\(\\hat{p}_s \\ln\\hat{p}_s\\) entre 0 et 1.\nCode de la figure 3.9 :Grassberger (1988) fourni la correction de référence :\\[\\begin{equation}\n  \\tag{3.43}\n  \\tilde{H}\n  = -\\sum^{f_{>0}}_{s=1}{\n    \\frac{n_s}{n} \\left( \\ln\\left( n \\right) - \\mathrm{\\Psi}\\left( n_s \\right)\n    -\\frac{{\\left( -1 \\right)}^{n_s}}{n_s + 1} \\right)\n  }.\n\\end{equation}\\]Grassberger (2003) l’perfectionnée :\\[\\begin{equation}\n  \\tag{3.44}\n  \\tilde{H}\n  = -\\sum^{f_{>0}}_{s=1}{\n    \\frac{n_s}{n} \\left( \\mathrm{\\Psi}\\left( n \\right) - \\mathrm{\\Psi}\\left( n_s \\right)\n    -{\\left( -1 \\right)}^{n_s} \\int^1_0{\\frac{t^{n_s - 1}}{1 + t} \\mathop{dt}} \\right)\n  }.\n\\end{equation}\\]Enfin, Schürmann (2004) l’généralisée pour définir une famille de corrections dépendant d’un paramètre \\(\\xi\\):\\[\\begin{equation}\n  \\tag{3.45}\n  \\tilde{H}\n  = -\\sum^{f_{>0}}_{s=1}{\n    \\frac{n_s}{n} \\left( \\mathrm{\\Psi}\\left( n \\right) - \\mathrm{\\Psi}\\left( n_s \\right)\n    - {\\left( -1 \\right)}^{n_s} \\int^{\\frac{1}{\\xi} - 1}_0{\\frac{t^{n_s - 1}}{1 + t} \\mathop{dt}} \\right)\n  }.\n\\end{equation}\\]Le biais d’estimation diminue avec \\(\\xi\\) mais l’erreur quadratique augmente.\nSchürmann suggère d’utiliser \\(\\xi=e^{-1/2}\\) comme meilleur compromis.La fonction ent_shannon permet toutes ces corrections.D’autres estimateurs peu utilisés en écologie sont disponibles dans le package entropy (Hausser Strimmer 2009).\nLa contraction de Stein (James Stein 1961) consiste à estimer la distribution des probabilités d’occurrence des espèces par la pondération optimale entre un estimateur à faible biais et un estimateur à faible variance.\nL’estimateur \\(\\hat{p}_s\\) est sans biais mais une variance importante.\nL’estimateur \\(1/S\\), si \\(S\\) est connu, est de variance nulle mais est très biaisé.\nComme le nombre d’espèces est en général inconnu, il doit être estimé par une méthode quelconque, mais de préférence le surestimant plutôt que le sous-estimant.\nL’estimateur de James-Stein (shrinkage estimator) optimal est\n\\[\\begin{equation}\n  \\tag{3.46}\n  \\tilde{p}_s = \\hat{\\lambda}\\frac{1}{\\hat{S}} + \\left( 1 - \\hat{\\lambda} \\right) \\hat{p}_s,\n\\end{equation}\\]où\n\\[\\begin{equation}\n  \\tag{3.47}\n  \\hat{\\lambda} = \\frac\n    {1 - \\sum^{f_{>0}}_{s=1}{\\left( \\hat{p}_s \\right)^2}}\n    {\\left( n - 1 \\right) \\sum^{f_{>0}}_{s=1}{\\left( \\frac{1}{\\hat{S}} - \\hat{p}_s \\right)^2}}.\n\\end{equation}\\]L’entropie est ensuite simplement estimée par l’estimateur plug- : \\(\\tilde{H} = -\\sum^{f_{>0}}_{s=1}{\\tilde{p}_s \\ln{\\tilde{p}_s}}\\).\nLe calcul sous R est le suivant :Le principe même de l’estimation rapproche la distribution de l’équiprobabilité des espèces et donc augmente l’entropie.\nL’estimation précédente ignore les espèces non observées.\nPour les inclure, le vecteur des abondance doit être allongé par autant de zéros que d’espèces estimées :Les fréquences sont estimées par la fonction freqs.shrink.\nLeur utilisation dans l’estimateur plug-donne le même résultat :Appliqué à des données de biodiversité aquatique, l’estimateur de James-Stein obtient de meilleurs résultats que celui de Chao et Shen (D. Liu et al. 2016) quand l’échantillonnage est réduit.","code":"\ntibble(x = c(0.0001, 1)) %>% \n  ggplot(aes(x)) + \n    stat_function(fun = function(x) -x * log(x)) +\n    labs(x = \"p\", y = \"H(p)\")\nbias_p <- function (p) {\n  p_s <-rnorm(10000, p, 0.01)\n  p * log(p) - mean(p_s * log(p_s))\n}\n\nbias <- function (p_s) {\n  # Applique bias_p à chaque valeur de p_s\n  sapply(p_s, bias_p)\n}\n\ntibble(x = c(0.05, 0.95)) %>% \n  ggplot(aes(x)) + \n    stat_function(fun = bias) +\n    geom_hline(yintercept = 0, lty = 2) +\n    labs(x = \"p\", y = \"Biais\")\nent_shannon(colSums(BCI), estimator = \"ChaoJost\")## # A tibble: 1 × 3\n##   estimator order entropy\n##   <chr>     <dbl>   <dbl>\n## 1 ChaoJost      1    4.28\nent_shannon(colSums(BCI), estimator = \"Grassberger\")## # A tibble: 1 × 3\n##   estimator   order entropy\n##   <chr>       <dbl>   <dbl>\n## 1 Grassberger     1    4.28\nent_shannon(colSums(BCI), estimator = \"Grassberger2003\")## # A tibble: 1 × 3\n##   estimator       order entropy\n##   <chr>           <dbl>   <dbl>\n## 1 Grassberger2003     1    4.28\nent_shannon(colSums(BCI), estimator = \"Schurmann\")## # A tibble: 1 × 3\n##   estimator order entropy\n##   <chr>     <dbl>   <dbl>\n## 1 Schurmann     1    4.28\nent_shannon(colSums(BCI), estimator = \"ZhangHz\")## # A tibble: 1 × 3\n##   estimator order entropy\n##   <chr>     <dbl>   <dbl>\n## 1 ZhangHz       1    4.27\nlibrary(\"entropy\")\nentropy.shrink(colSums(BCI))## Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.0021## [1] 4.275689\n## attr(,\"lambda.freqs\")\n## [1] 0.002074043\nentropy.shrink(c(colSums(BCI), rep(0, bci_f_0)))## Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.002## [1] 4.276543\n## attr(,\"lambda.freqs\")\n## [1] 0.002041748\nent_shannon(freqs.shrink(c(colSums(BCI), rep(0, bci_f_0))))## Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.002## # A tibble: 1 × 3\n##   estimator order entropy\n##   <chr>     <dbl>   <dbl>\n## 1 naive         1    4.28"},{"path":"chap-MesuresNeutres.html","id":"sec-Hurlbert","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.4 Indice de Hurlbert","text":"","code":""},{"path":"chap-MesuresNeutres.html","id":"définition-2","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.4.1 Définition","text":"L’indice de Hurlbert (1971) est l’espérance du nombre d’espèces observées dans un échantillon de taille \\(k\\) choisie :\\[\\begin{equation}\n  \\tag{3.48}\n  _{k}S = \\sum^S_{s=1}{\\left[ 1 - {\\left( 1 - p_s \\right)}^k \\right]}.\n\\end{equation}\\]Chaque terme de la somme est la probabilité d’observer au moins une fois l’espèce correspondante.L’augmentation de la valeur de \\(k\\) permet de donner plus d’importance aux espèces rares.L’indice peut être converti en nombre équivalent d’espèces (Dauby Hardy 2012), c’est-à-dire le nombre d’espèces équiprobables nécessaire pour obtenir la même diversité, notés \\(_{k}D\\) à partir de la relation\\[\\begin{equation}\n  \\tag{3.49}\n  _{k}S = {_{k}D} \\left[ 1 - {\\left( 1 - \\frac{1}{_{k}D} \\right)}^k \\right].\n\\end{equation}\\]L’équation doit être résolue pour obtenir \\(_{k}D\\) à partir de la valeur de \\(_{k}S\\) estimée, numériquement pour \\(k>3\\).Dans deux cas particuliers, les nombres équivalents d’espèces de Hurlbert sont identiques aux nombres de Hill : \\(_{2}D = {^{2}\\!D}\\) et \\(_{\\infty}D = {^{0}\\!D}\\).Pour les autres ordres entiers de diversité, il existe une correspondance parfaite entre les deux mesures (Chao et al. 2014, Annexe S2) : la connaissance de l’une permet d’obtenir l’autre. Pour \\(k>1\\), (Leinster Cobbold 2012)\\[\\begin{equation}\n  \\tag{3.50}\n  _{k}S = k + \\sum_{q=2}^{k}{\\binom{k}{q} \\left( -1 \\right)^{q + 1} \\left( ^{q}\\!D \\right)^{1-q}}.\n\\end{equation}\\]vu que \\(^{0}\\!D\\) égale \\(_{\\infty}D\\), donc \\(_{\\infty}S = {^{0}\\!D}\\) (3.49).Inversement, pour \\(q > 1\\):\\[\\begin{equation}\n  \\tag{3.51}\n  (^{q}\\!D)^{1-q} = q + \\sum_{k=2}^{q}{\\binom{q}{k} \\left( -1 \\right)^{k + 1} {_{k}S}}.\n\\end{equation}\\]Pour \\(q=1\\), la relation est (Mao 2007)\n\\[\\begin{equation}\n  \\tag{3.52}\n  ^{1}\\!H = -1 + \\sum_{k=2}^{\\infty}{\\frac{_{k}S}{k \\left( k - 1 \\right)}}.\n\\end{equation}\\]","code":""},{"path":"chap-MesuresNeutres.html","id":"estimation-1","chapter":"3 Mesures classiques de la diversité \\(\\alpha\\) ou \\(\\gamma\\)","heading":"3.4.2 Estimation","text":"Hurlbert fournit un estimateur non biaisé de son indice (\\(n\\) est la taille de l’échantillon, \\(n_s\\) le nombre d’individus de l’espèce \\(s\\)) :\\[\\begin{equation}\n  \\tag{3.53}\n  _k{\\tilde{S}}\n  = \\sum_{s=1}^{f_{>0}}{\\left[ 1-{\\binom{n - n_s}{k}}/{\\binom{n}{k}} \\right]}.\n\\end{equation}\\]Dauby Hardy (2012) montrent que cet estimateur est très peu sensible à la taille de l’échantillon, et obtient de meilleurs résultats sur ce point que les estimateurs de Chao et Shen pour l’indice de Shannon ou du nombre d’espèces.\nW. Smith Grassle (1977) ont calculé sa variance.Le calcul de la diversité de Hurlbert est possible dans divent :","code":"\n# Indice de Hurlbert (probabilités)\nent_hurlbert(as_probabilities(colSums(BCI)), k = 2)## # A tibble: 1 × 5\n##   site           weight estimator order entropy\n##   <chr>           <dbl> <chr>     <dbl>   <dbl>\n## 1 site_402217706      1 naive         2    1.97\n# Estimateur sans biais (abondances)\nent_hurlbert(colSums(BCI), k = 2)## # A tibble: 1 × 3\n##   estimator order entropy\n##   <chr>     <dbl>   <dbl>\n## 1 Hurlbert      2    1.97\n# Nombre effectif d'espèces\ndiv_hurlbert(colSums(BCI), k = 2)## # A tibble: 1 × 3\n##   estimator order diversity\n##   <chr>     <dbl>     <dbl>\n## 1 Hurlbert      2      38.1"},{"path":"entropie.html","id":"entropie","chapter":"4 Entropie","heading":"4 Entropie","text":"L’entropie est la surprise moyenne apportée par l’observation des individus d’une communauté, d’autant plus grande qu’un individu appartient à une espèce plus rare.\nL’entropie HCDT permet d’unifier les indices classiques de diversité : son paramètre, appelé ordre, fixe l’importance donnée aux espèces rares. L’entropie d’ordre 0 est la richesse ; celle d’ordre 1, l’indice de Shannon ; celle d’ordre 2, celui de Simpson.\nL’entropie est la moyenne du logarithme déformé de la rareté des espèces, définie comme l’inverse de leur probabilité.L’entropie va de pair avec la diversité au sens strict (Nombres de Hill) : le nombre d’espèces équiprobables dont l’entropie est la même que celle de la communauté réelle.\nLa diversité est l’exponentielle déformée de l’entropie.\nLes profils de diversité représentent la diversité en fonction de son ordre et permettent la comparaison de communautés.L’estimation de la diversité est difficile pour des ordres inférieurs à \\(0,5\\) dans des taxocènes très divers comme les arbres des forêts tropicales.L’entropie peut être entendue comme la surprise moyenne fournie par l’observation d’un échantillon.\nC’est intuitivement une bonne mesure de diversité (Pielou 1975).\nSes propriétés mathématiques permettent d’unifier les mesures de diversité dans un cadre général.","code":""},{"path":"entropie.html","id":"définition-de-lentropie","chapter":"4 Entropie","heading":"4.1 Définition de l’entropie","text":"Les textes fondateurs sont Davis (1941) et surtout Theil (1967) en économétrie, et Shannon (1948; 1963) pour la mesure de la diversité.\nUne revue est fournie par Maasoumi (1993).Considérons une expérience dont les résultats possibles sont \\(\\{r_1, r_2, \\dots , \\ r_S\\}\\).\nLa probabilité d’obtenir \\(r_s\\) est \\(p_s\\), et \\(\\mathbf{p}=(p_1, p_2, \\dots, p_S)\\) est le vecteur composé des probabilités d’obtenir chaque résultat.\nLes probabilités sont connues priori.\nTout ce qui suit est vrai aussi pour des valeurs de \\(r\\) continues, dont connaîtrait la densité de probabilité.considère maintenant un échantillon de valeurs de \\(r\\).\nLa présence de \\(r_s\\) dans l’échantillon est peu étonnante si \\(p_s\\) est grande : elle apporte peu d’information supplémentaire par rapport à la simple connaissance des probabilités.\nEn revanche, si \\(p_s\\) est petite, la présence de \\(r_s\\) est surprenante.\ndéfinit donc une fonction d’information, \\((p_s)\\), décroissante quand la probabilité augmente, de \\((0) > 0\\) (éventuellement \\(+\\infty\\)) à \\((1) = 0\\), parce qu’observer un résultat certain n’apporte aucune information.\nChaque valeur observée dans l’échantillon apporte une certaine quantité d’information, dont la somme est l’information de l’échantillon.\nPatil Taillie (1982) appellent l’information “rareté”.La quantité d’information attendue de l’expérience est \\(\\sum^S_{s=1}{p_s (p_s) = H(\\mathbf{p})}\\).\nSi choisit \\((p_s) = -\\ln(p_s)\\), \\(H(\\mathbf{p})\\) est l’indice de Shannon, mais bien d’autres formes de \\((p_s)\\) sont possibles.\n\\(H(\\mathbf{p})\\) est appelée entropie.\nC’est une mesure de l’incertitude (de la volatilité) du résultat de l’expérience.\nSi le résultat est certain (une seule valeur \\(p_S\\) vaut 1), l’entropie est nulle.\nL’entropie est maximale quand les résultats sont équiprobables.Si \\(\\mathbf{p}\\) est la distribution des probabilité des espèces dans une communauté, Patil Taillie (1982) montrent que :Si \\((p_s) = (1 - p_s) / {p_s}\\), alors \\(H(\\mathbf{p})\\) est le nombre d’espèces \\(S\\) moins 1 ;Si \\((p_s) = -\\ln(p_s)\\), alors \\(H(\\mathbf{p})\\) est l’indice de Shannon ;Si \\((p_s) = 1 - p_s\\), alors \\(H(\\mathbf{p})\\) est l’indice de Simpson.Ces trois fonctions d’information sont représentées en figure ??.Le code R nécessaire pour réaliser la figure est :\nFigure 4.1: Valeur de \\(p_{s}(p_s)\\) dans le nombre d’espèces (trait plein), l’indice de Shannon (pointillés longs) et l’indice de Simpson (pointillés). Les espèces rares contribuent peu, sauf pour le nombre d’espèces.\nLa contribution de chaque espèce à la valeur totale de l’entropie est représentée figure 4.1.Code R :","code":"\nI0 <- function(p) (1- p) / p\nI1 <- function(p) -log(p)\nI2 <- function(p) 1 - p\ntibble(x = c(0, 1)) %>% \n  ggplot(aes(x)) + \n    stat_function(fun = I0) +\n    stat_function(fun = I1, lty = 2) +\n    stat_function(fun = I2, lty = 3) +\n    coord_cartesian(ylim = c(0, 10)) +\n    labs(x = \"p\", y = \"I(p)\")\nH0 <- function(p) 1 - p\nH1 <- function(p) -p * log(p)\nH2 <- function(p) p * (1 - p)\ntibble(x = c(0.001, 1)) %>% \n  ggplot(aes(x)) + \n    stat_function(fun = H0) +\n    stat_function(fun = H1, lty = 2) +\n    stat_function(fun = H2, lty = 3) +\n    labs(x = \"p\", y = \"H(p)\")"},{"path":"entropie.html","id":"entropie-relative","chapter":"4 Entropie","heading":"4.2 Entropie relative","text":"Considérons maintenant les probabilités \\(q_s\\) formant l’ensemble \\(\\mathbf{q}\\) obtenues par la réalisation de l’expérience.\nElles sont différentes des probabilités \\(p_s\\), par exemple parce que l’expérience ne s’est pas déroulée exactement comme prévu.\ndéfinit le gain d’information \\((q_s, p_s)\\) comme la quantité d’information supplémentaire fournie par l’observation d’un résultat de l’expérience, connaissant les probabilités priori.\nLa quantité totale d’information fournie par l’expérience, \\(\\sum^S_{s=1}{q_s (q_s, p_s)} = H(\\mathbf{q}, \\mathbf{p})\\), est souvent appelée entropie relative.\nElle peut être vue comme une distance entre la distribution priori et la distribution posteriori.\nIl est possible que les distributions \\(\\mathbf{p}\\) et \\(\\mathbf{q}\\) soit identiques, que le gain d’information soit donc nul, mais les estimateurs empiriques n’étant pas exactement égaux entre eux, des tests de significativité de la valeur de \\(\\hat{H}(\\mathbf{q},\\mathbf{p})\\) seront nécessaires.Quelques formes possibles de \\(H(\\mathbf{q}, \\mathbf{p})\\) sont :La divergence de Kullback-Leibler (Kullback Leibler 1951) connue par les économistes comme l’indice de dissimilarité de Theil (1967) :\n\\[\\begin{equation}\n\\tag{4.1}\nT = \\sum^S_{s=1}{q_{s}\\ln\\frac{q_s}{p_s}};\n\\end{equation}\\]Sa proche parente, appelée parfois deuxième mesure de Theil (Conceição Ferreira 2000), qui inverse simplement les rôles de \\(p\\) et \\(q\\):\n\\[\\begin{equation}\n\\tag{4.2}\nL = \\sum^S_{s=1}{p_{s}\\ln\\frac{p_s}{q_s}}.\n\\end{equation}\\]\nFigure 4.2: Valeur de \\(q \\ln(q / p)\\) en fonction de \\(p\\) et \\(q\\). La divergence de Kullback-Leibler est la somme de cette valeur pour toutes les espèces\nL’entropie relative est essentielle pour la définition de la diversité \\(\\beta\\) présentée dans le chapitre ??.\nEn se limitant à la diversité \\(\\alpha\\), peut remarquer que l’indice de Shannon est la divergence de Kullback-Leibler entre la distribution observée et l’équiprobabilité des espèces (Marcon et al. 2012).La contribution à la divergence de chaque couple \\((p_s, q_s)\\) est représentées en figure 4.2.\nElle est positive quand \\(q_s > p_s\\) (la valeur observée est plus grande que la valeur attendue), et croît avec \\(q_s\\) pour \\(p_s\\) fixé.\nElle tend vers l’infini quand \\(p_s \\0\\).\nLes valeurs les plus négatives ne sont pas obtenues pour les valeurs minimales de \\(q\\) parce que les évènements très rarement observés influent peu sur la quantité d’information totale.\nLe minimum \\(-e^{-1} \\approx 0.37\\) est atteint pour \\(p_s = 1\\) et \\(q_s = e^{-1}\\), la valeur qui annule la dérivée de \\(q \\ln(q)\\).\nEn somme, la divergence de Kullback-Leibler est surtout influencée par les évènements beaucoup plus observés qu’attendus.Le code R nécessaire pour réaliser la figure est :","code":"\np <- q <- seq(0.01, 1, .01)\nKB <- function(p, q) q * log(q / p)\nxyz <- outer(p, q, FUN = \"KB\")\nlibrary(\"sp\")\nimage(\n  xyz, \n  col = rainbow(n = 100, alpha = 0.8), \n  xlab = \"p\", \n  ylab = \"q\", \n  asp = 1\n)\ncontour(\n  xyz, \n  levels = c(seq(-.3, 0, .1), c(.2, .5), seq(1, 4, 1)), \n  labcex = 1, \n  add = T\n)"},{"path":"entropie.html","id":"lappropriation-de-lentropie-par-la-biodiversité","chapter":"4 Entropie","heading":"4.3 L’appropriation de l’entropie par la biodiversité","text":"MacArthur (1955) est le premier à avoir introduit la théorie de l’information en écologie (Ulanowicz 2001).\nMacArthur s’intéressait aux réseaux trophiques et cherchait à mesurer leur stabilité : l’indice de Shannon qui comptabilise le nombre de relations possibles lui paraissait une bonne façon de l’évaluer.\nMais l’efficacité implique la spécialisation, ignorée dans \\(H\\) qui est une mesure neutre (toutes les espèces y jouent le même rôle).\nMacArthur abandonné cette voie.Les premiers travaux consistant à généraliser l’indice de Shannon sont dus à Rényi (1961).\nL’entropie d’ordre \\(q\\) de Rényi est\\[\\begin{equation}\n^{q}\\!R =\\frac{1}{1 - q \\ln\\sum^S_{q=1}{p^q_s}}.\n\\end{equation}\\]Rényi pose également les axiomes pour une mesure d’entropie \\(R(\\mathbf{p})\\), où \\(\\mathbf{p}=(p_1, p_2, \\dots, p_S)\\):La symétrie : les espèces doivent être interchangeables, aucune n’de rôle particulier et leur ordre est indifférent ;La mesure doit être continue par rapport aux probabilités ;La valeur maximale est atteinte si toutes les probabilités sont égales.Il montre que \\(^{q}\\!R\\) respecte les 3 axiomes.Patil Taillie (1982) ont montré de plus que :L’introduction d’une espèce dans une communauté augmente sa diversité (conséquence de la décroissance de \\(g(p_s)\\)) ;Le remplacement d’un individu d’une espèce fréquente par un individu d’une espèce plus rare augmente l’entropie à condition que \\(R(\\mathbf{p})\\) soit concave.\nDans la littérature économique sur les inégalités, cette propriété est connue sous le nom de Pigou-Dalton (Dalton 1920).Hill (1973) transforme l’entropie de Rényi en nombres de Hill, qui en sont simplement l’exponentielle :\\[\\begin{equation}\n  \\tag{4.3}\n  ^{q}\\!D = {\\left(\\sum^S_{s=1}{p^q_s}\\right)}^{\\frac{1}{1 - q}}.\n\\end{equation}\\]Le souci de Hill était de rendre les indices de diversité intelligibles après l’article remarqué de Hurlbert (1971) intitulé “le non-concept de diversité spécifique”.\nHurlbert reprochait à la littérature sur la diversité sa trop grande abstraction et son éloignement des réalités biologiques, notamment en fournissant des exemples dans lesquels l’ordre des communautés n’est pas le même selon l’indice de diversité choisi.\nLes nombres de Hill sont le nombre d’espèces équiprobables donnant la même valeur de diversité que la distribution observée.\nIls sont des transformations simples des indices classiques :\\(^{0}\\!D\\) est le nombre d’espèces ;\\(^{1}\\!D = e^H\\), l’exponentielle de l’indice de Shannon ;\\(^{2}\\!D = {1} / {(1- E)}\\), l’inverse de l’indice de concentration de Simpson, connu sous le nom d’indice de Stoddart (1983).Ces résultats avaient déjà été obtenus avec une autre approche par MacArthur (1965) et repris par Adelman (1969) dans la littérature économique.Les nombres de Hill sont des “nombres effectifs” ou “nombres équivalents”.\nLe concept été défini rigoureusement par Gregorius (1991), d’après Wright (1931) (qui avait le premier défini la taille effective d’une population) : étant donné une variable caractéristique (ici, l’entropie) fonction seulement d’une variable numérique (ici, le nombre d’espèces), dans un cas idéal (ici, l’équiprobabilité des espèces), le nombre effectif est la valeur de la variable numérique pour laquelle la variable caractéristique est celle du jeu de données.Gregorius (2014) montre que de nombreux autres indices de diversité sont acceptables dans le sens où ils vérifient les axiomes précédents et, de plus, que la diversité d’un assemblage de communautés est obligatoirement supérieure à la diversité moyenne de ces communautés (l’égalité n’étant possible que si les communautés sont toutes identiques).\nCette dernière propriété sera traitée en détail dans la partie consacrée à la décomposition de la diversité.\nCes indices doivent vérifier deux propriétés : leur fonction d’information doit être décroissante, et ils doivent être une fonction strictement concave de \\(p_s\\).\nParmi les possibilités, \\((p_s) = \\cos{(p_s \\pi / 2)}\\) est envisageable par exemple : le choix de la fonction d’information est virtuellement illimité, mais seules quelques unes seront interprétables clairement.Un nombre équivalent d’espèces existe pour tous ces indices, il est toujours égal à l’inverse de l’image de l’indice par la réciproque de la fonction d’information :\\[\\begin{equation}\n  \\tag{4.4}\n  D = \\frac{1}{^{-1} \\left( \\sum^S_{s=1}{p_s (p_s)} \\right)}.\n\\end{equation}\\]D’autres entropies ont été utilisées, avec plus ou moins de succès.\nPar exemple, Ricotta Avena (2003) proposent d’utiliser la fonction d’information \\((p_s) = -\\ln(k_s)\\) où \\(k_s\\) est la dissimilarité totale de l’espèce \\(s\\) avec les autres (par exemple, la somme des distances aux autres espèces dans un arbre phylogénétique, voir section ??), normalisée pour que \\(\\sum_s{k_s} = 1\\).\nAinsi, les espèces les plus originales apportent peu d’information, ce qui n’est pas très intuitif.\nLes auteurs montrent que leur mesure est la somme de l’entropie de Shannon et de la divergence de Kullback-Leibler entre les probabilités et les dissimilarités des espèces.\nRicotta Szeidl (2006) ont défini plus tard une entropie augmentant avec l’originalité de chaque espèce, présentée au chapitre ??.","code":""},{"path":"entropie.html","id":"entropie-hcdt","chapter":"4 Entropie","heading":"4.4 Entropie HCDT","text":"Tsallis (1988) propose une classe de mesures appelée entropie généralisée, définie par Havrda Charvát (1967) pour la première fois et redécouverte plusieurs fois, notamment par Daróczy (1970), d’où son nom entropie HCDT (voir Mendes et al. (2008), page 451, pour un historique complet) :\\[\\begin{equation}\n  \\tag{4.5}\n  ^{q}\\!H = \\frac{1}{q-1} \\left( 1 - \\sum^S_{s=1}{p^q_s} \\right).\n\\end{equation}\\]Tsallis montré que les indices de Simpson et de Shannon étaient des cas particuliers d’entropie généralisée, retrouvant, sans faire le rapprochement (Ricotta 2005a), la définition d’un indice de diversité de Patil Taillie (1982).Ces résultats ont été complétés par d’autres et repris en écologie par Keylock (2005) et Jost (2006, 2007).\nLà encore :Le nombre d’espèces moins 1 est \\(^{0}\\!H\\);L’indice de Shannon est \\(^{1}\\!H\\);L’indice de Gini-Simpson est \\(^{2}\\!H\\).L’entropie HCDT est particulièrement attractive parce que sa relation avec la diversité au sens strict est simple, après introduction du formalisme adapté (les logarithmes déformés).\nSon biais d’estimation peut être corrigé globalement, et non seulement pour les cas particuliers (nombre d’espèces, Shannon, Simpson).\nEnfin, sa décomposition sera présentée en détail dans le chapitre ??.","code":""},{"path":"entropie.html","id":"logarithmes-déformés","chapter":"4 Entropie","heading":"4.5 Logarithmes déformés","text":"L’écriture de l’entropie HCDT est largement simplifiée en introduisant le formalisme des logarithmes déformés (Tsallis 1994).\nLe logarithme d’ordre \\(q\\) est défini par\n\\[\\begin{equation}\n  \\tag{4.6}\n  \\ln_q{x} = \\frac{x^{1-q} - 1}{1 - q},\n\\end{equation}\\]\ndont la forme est identique à la transformation de Box Cox (1964) utilisée en statistiques pour normaliser une variable.Le logarithme déformé converge vers le logarithme naturel quand \\(q \\1\\) (figure 4.3).\nFigure 4.3: Valeur du logarithme d’ordre \\(q\\) de probabilités entre 0 et 1 pour différentes valeurs de \\(q\\): \\(q = 0\\) (pointillés longs rouges), la courbe est une droite ; \\(q = 1\\) (trait plein) : logarithme naturel ; \\(q = 2\\) (pointillés courts bleus) : la courbe la même forme que le logarithme naturel pour les valeurs positives de \\(q\\); \\(q = -1\\) (pointillés alternés verts) : la courbe est convexe pour les valeurs négatives de \\(q\\).\nLe code R nécessaire pour réaliser la figure est :Sa fonction inverse est l’exponentielle d’ordre \\(q\\):\\[\\begin{equation}\n  \\tag{4.7}\n  e^x_q = \\left[ 1 + \\left( 1 - q \\right) x \\right]^{\\frac{1}{1 - q}}.\n\\end{equation}\\]Enfin, le logarithme déformé est subadditif :\\[\\begin{equation}\n  \\tag{4.8}\n  \\ln_q\\left( xy \\right)\n  = \\ln_q{x} + \\ln_q{y}\n    - \\left( q - 1 \\right) \\left( \\ln_q{x} \\right) \\left( \\ln_q{y} \\right).\n\\end{equation}\\]Ses propriétés sont les suivantes :\\[\\begin{equation}\n  \\tag{4.9}\n  \\ln_q\\frac{1}{x} = -x^{q - 1} \\ln_q{x};\n\\end{equation}\\]\\[\\begin{equation}\n  \\tag{4.10}\n  \\ln_q\\left( xy \\right) = \\ln_q{x} + x^{1-q} \\ln_q{y};\n\\end{equation}\\]\\[\\begin{equation}\n  \\tag{4.11}\n  \\ln_q\\left( \\frac{x}{y} \\right)\n  = \\ln_q{x} - {\\left( \\frac{x}{y} \\right)}^{1 - q} \\ln_q{y};\n\\end{equation}\\]et\\[\\begin{equation}\n  \\tag{4.12}\n  e^{x + y}_q = e_q^x e_q^{\\frac{y}{1 + \\left( 1 - q \\right) x}}.\n\\end{equation}\\]Si \\(q > 1\\), \\(\\mathop{\\lim}_{x \\+\\infty}(\\ln_q{x}) = {1} / {(q - 1)}\\), donc \\(e_q^x\\) n’est pas définie pour \\(x > 1 / (q - 1)\\).La dérivée du logarithme déformé est, quel que soit \\(q\\),\n\\[\\begin{equation}\n  \\tag{4.13}\n  \\ln'_q\\left( x \\right) = x^{-q}.\n\\end{equation}\\]Les dérivées première et seconde de l’exponentielle déformée sont, quel que soit \\(q\\):\n\\[\\begin{equation}\n  \\tag{4.14}\n  \\exp'_q\\left( x \\right) = \\left( e_q^x \\right)^{q};\n\\end{equation}\\]\n\\[\\begin{equation}\n  \\tag{4.15}\n  \\exp''_q\\left( x \\right) = \\left( e_q^x \\right)^{2q - 1}.\n\\end{equation}\\]Ces fonctions sont implémentées dans le package divent : ln_q(x, q) et exp_q(x, q).L’entropie d’ordre \\(q\\) s’écrit\\[\\begin{equation}\n  \\tag{4.16}\n  ^{q}\\!H\n  = \\frac{1}{q - 1} \\left( 1 - \\sum^S_{s=1}{p^q_s} \\right)\n  = -\\sum_s{p^q_s} \\ln_q{p_s}\n  = \\sum_s{p_s}{\\ln_q\\frac{1}{p_s}}.\n\\end{equation}\\]Ces trois formes sont équivalentes mais les deux dernières s’interprètent comme une généralisation de l’entropie de Shannon (Marcon et al. 2014).\nLa dernière est la plus intéressante parce qu’elle permet de définir l’entropie en général comme la moyenne du logarithme de l’inverse des probabilités, que nous appellerons la rareté des espèces.Le calcul de \\(^{q}\\!H\\) peut se faire avec la fonction ent_tsallis de la librairie divent :","code":"\nln0 <- function(p) lnq(p, 0)\nln2 <- function(p) lnq(p, 2)\nlnm1 <- function(p) lnq(p, -1)\ntibble(x = c(0, 1)) %>% \n  ggplot(aes(x)) + \n    stat_function(fun = log) +\n    stat_function(fun = ln0, lty = 2, col = \"red\") +\n    stat_function(fun = ln2, lty = 3, col = \"blue\") +\n    stat_function(fun = lnm1, lty = 4, col = \"green\") +\n    coord_cartesian(ylim = c(-4, 0)) +\n    labs(x = \"p\", y = expression(ln[q](p)))\nent_tsallis(bci_prob, q= 1.5)## # A tibble: 1 × 3\n##   estimator order entropy\n##   <chr>     <dbl>   <dbl>\n## 1 naive       1.5    1.72"},{"path":"entropie.html","id":"entropie-et-diversité","chapter":"4 Entropie","heading":"4.6 Entropie et diversité","text":"voit immédiatement que l’entropie de Tsallis est le logarithme d’ordre \\(q\\) du nombre de Hill correspondant, comme l’entropie de Rényi en est le logarithme naturel :\\[\\begin{equation}\n  \\tag{4.17}\n  ^{q}\\!H = \\ln_q{^{q}\\!D};\n\\end{equation}\\]\\[\\begin{equation}\n  \\tag{4.18}\n  ^{q}\\!D = e_q^{^{q}\\!H}.\n\\end{equation}\\]L’entropie est utile pour les calculs : la correction des biais d’estimation notamment.\nLes nombres de Hill, ou nombres équivalents d’espèces ou nombres effectif d’espèces permettent une appréhension plus intuitive de la notion de biodiversité (Jost 2006).\nEn raison de leurs propriétés, notamment de décomposition (voir le chapitre ??), Jost (2007) les appelle “vraie diversité”.\nHoffmann Hoffmann (2008) critiquent cette définition totalitaire et fournissent une revue historique plus lointaine sur les origines de ces mesures.\nJost (2009) reconnaît qu’un autre terme aurait pu être choisi (“diversité neutre” ou “diversité mathématique” par exemple).Dauby Hardy (2012) écrivent “diversité au sens strict” ; Gregorius (2010) “diversité explicite”.Quoi qu’il en soit, les nombres de Hill respectent le principe de réplication (voir Chao, Chiu, Jost (2010), section 3 pour une discussion et un historique) : si \\(\\) communautés de même taille, de même niveau de diversité \\(D\\), mais sans espèces en commun sont regroupées dans une méta-communauté, la diversité de la méta-communauté doit être \\(\\times D\\).L’intérêt de ces approches est de fournir une définition paramétrique de la diversité, qui donne plus ou moins d’importance aux espèces rares :\\(^{-\\infty}\\!D = {1} / {\\min(p_S)}\\) est l’inverse de la proportion de la communauté représentée par l’espèce la plus rare (toutes les autres espèces sont ignorées).\nLe biais d’estimation est incontrôlable : l’espèce la plus rare n’est pas dans l’échantillon tant que l’inventaire n’est pas exhaustif ;\\(^{0}\\!D\\) est le nombre d’espèces (alors que \\(^{0}\\!H\\) est le nombre d’espèces moins 1).\nC’est la mesure classique qui donne le plus d’importance aux espèces rares : toutes les espèces ont la même importance, quel que soit leur effectif en termes d’individus.\nIl est bien adapté à une approche patrimoniale, celle du collectionneur qui considère que l’existence d’une espèce supplémentaire un intérêt en soi, par exemple parce qu’elle peut contenir une molécule valorisable.\nComme les espèces rares sont difficiles à échantillonner, le biais d’estimation est très important, et sa résolution généré une littérature en soi (section 3.1) ;\\(^{1}\\!D\\) est l’exponentielle de l’indice de Shannon donne la même importance à tous les individus.\nIl est adapté à une approche d’écologue, intéressé par les interactions possibles : le nombre de combinaisons d’espèces en est une approche satisfaisante.\nLe biais d’estimation est sensible ;\\(^{2}\\!D\\) est l’inverse de l’indice de concentration de Gini-Simpson donne moins d’importance aux espèces rares.\nHill (1973) l’appelle “le nombre d’espèces très abondantes”.\nIl comptabilise les interactions possibles entre paires d’individus : les espèces rares interviennent dans peu de paires, et influent peu sur l’indice.\nEn conséquence, le biais d’estimation est très petit ; de plus, un estimateur non biaisé existe ;\\(^{\\infty}\\!D = {1} / {d}\\) est l’inverse de l’indice de Berger-Parker (Berger Parker 1970) qui est la proportion de la communauté représentée par l’espèce la plus abondante : \\(d = \\max(\\mathbf{p})\\).\nToutes les autres espèces sont ignorées.Le calcul de \\(^{q}\\!D\\) peut se faire avec la fonction div_hill de la librairie divent :Les propriétés mathématiques de la diversité ne sont pas celles de l’entropie.\nL’entropie doit être une fonction concave des probabilités comme l’vu plus haut, mais pas la diversité (un exemple de confusion est fourni par Gadagkar (1989), qui reproche à \\(^{2}\\!D\\) de ne pas être concave).\nL’entropie est une moyenne pondérée par les probabilités de la fonction d’information, c’est donc une fonction linéaire des probabilités, propriété importante pour définir l’entropie \\(\\alpha\\) (section ??) comme la moyenne des entropies de plusieurs communautés, ou l’entropie phylogénétique (chapitre ??) comme la moyenne de l’entropie sur les périodes d’un arbre.\nLa diversité n’est pas une fonction linéaire des probabilités : la diversité moyenne n’est en général pas la moyenne des diversités.","code":"\ndiv_hill(bci_prob, q = 1.5)## # A tibble: 1 × 3\n##   estimator order diversity\n##   <chr>     <dbl>     <dbl>\n## 1 naive       1.5      49.6"},{"path":"entropie.html","id":"synthèse-1","chapter":"4 Entropie","heading":"4.7 Synthèse","text":"L’inverse de la probabilité d’une espèce, \\(1/p_s\\), définit sa rareté.\nL’entropie est la moyenne du logarithme de la rareté :\\[\\begin{equation}\n  \\tag{4.19}\n  ^{q}\\!H\n  = \\frac{1}{q-1} \\left( 1 - \\sum^S_{s=1}{p^q_s} \\right)\n  = \\sum_s{p_s}\\ln_q\\frac{1}{p_s}.\n\\end{equation}\\]La diversité est son exponentielle :\\[\\begin{equation}\n  \\tag{4.20}\n  ^{q}\\!D = e_q^{^{q}\\!H}.\n\\end{equation}\\]","code":""},{"path":"entropie.html","id":"profils-de-diversité","chapter":"4 Entropie","heading":"4.8 Profils de diversité","text":"Leinster Cobbold (2012), après Hill (1973), Patil Taillie (1982), Tothmeresz (1995) et Kindt, Van Damme, Simons (2006), recommandent de tracer des profils de diversité, c’est-à-dire la valeur de la diversité \\(^{q}\\!D\\) en fonction de l’ordre \\(q\\) (figure 4.4) pour comparer plusieurs communautés.\nUne communauté peut être déclarée plus diverse qu’une autre si son profil de diversité est au-dessus de l’autre pour toutes les valeurs de \\(q\\).\nSi les courbes se croisent, il n’y pas de relation d’ordre (Tothmeresz 1995).Lande, DeVries, Walla (2000) montrent que si la diversité de Simpson et la richesse de deux communautés n’ont pas le même ordre, alors les courbes d’accumulation du nombre d’espèces en fonction du nombre d’individus échantillonnés se croisent aussi.\nFigure 4.4: Profils de diversité des quatre carrés de la parcelle 6 de Paracou. La correction du biais d’estimation est celle de Chao et Jost. Le carré 2 est plus divers que le carré 4, mais pas que les carrés 1 et 3, qui sont plus divers dans les grands ordres de diversité. Le profil de diversité est tracé ici jusqu’à l’ordre \\(q = 3\\).\nCode R pour réaliser la figure 4.4 :Pallmann et al. (2012) ont développé un test statistique pour comparer la diversité de deux communautés pour plusieurs valeurs de \\(q\\) simultanément.C. Liu et al. (2006) nomment séparables des communautés dont les profils ne se croisent pas.\nIls montrent que des communautés peuvent être séparables en selon un profil de diversité de \\(^{q}\\!D\\) sans l’être forcément selon un profil de diversité de Hurlbert (section 3.4), et inversement.\nIls montrent que les communautés séparables selon un troisième type de profil, celui de la queue de distribution (Patil Taillie 1982), le sont dans tous les cas.\nLe profil de la queue de distribution est construit en classant les espèces de la plus fréquente à la plus rare et en traçant la probabilité qu’un individu appartienne à une espèce plus rare que l’espèce en abscisse (figure 4.5).\nFigure 4.5: Profil de queue de distribution calculé pour les carrés de la parcelle 6 de Paracou. En abscisse : rang de l’espèce dans le classement de la plus fréquente à la plus rare ; en ordonnée : probabilité qu’un individu de la communauté appartienne à une espèce plus rare. Les profils de queue de distribution se croisent d’autant plus tôt qu’ils se croisent pour de grands ordres de diversité dans la figure 4.4.\nCode R :Les coordonnées des points du profil sont définies par\n\\[\\begin{equation}\n  \\tag{4.21}\n  y(x) = \\sum_{s=x+1}^{S}{p_{[s]}},\\ x\\\\{0, 1, \\dots, S\\}.\n\\end{equation}\\]\\(p_{[s]}\\) est la probabilité de l’espèce \\(s\\); les espèces sont classées par probabilité décroissante.Ce profil est exhaustif (toutes les espèces sont représentées) alors que les autres profils de diversité ne sont représentés que pour un intervalle restreint du paramètre et qu’un croisement de courbes peut se produire au-delà.\nEn revanche, il ne prend pas en compte les espèces non observées.Fattorini Marcheselli (1999) proposent un test pour comparer deux profils de queue de distribution à partir d’échantillonnages multiples (nécessaires pour évaluer la variance de chacune des probabilités) mais qui néglige les espèces non observées.","code":"\nparacou_6_abd %>% \n  # Suppression de \"subplot_\" dans les noms des carrés\n  mutate(site = str_replace(.$site, \"subplot_\", \"\")) %>% \n  # Profil\n  profile_hill(orders = seq(0, 3, .1), estimator = \"ChaoJost\") %>%\n  autoplot() +\n  labs(color = \"Carré\")\nparacou_6_abd %>%\n  # Transformation en probabilités\n  as_probabilities() %>%\n  # Elimination des colonnes de description\n  as.matrix() %>% \n  # Tri des espèces par ordre croissant de probabilité\n  apply(MARGIN = 1, FUN = sort) %>% \n  # Cumul des probabilités. Attention: apply a transposé la matrice\n  apply(MARGIN = 2, FUN = cumsum) %>% \n  # Classement par valeurs décroissantes\n  apply(MARGIN = 2, FUN = rev) %>% \n  # Création d'un tibble pour le graphique\n  as_tibble() %>% \n  # Nom des colonnes: 1 à 4\n  rename_with(~ str_replace(., \"V\", \"\")) %>% \n  # Ajout d'une colonne pour l'ordre\n  mutate(rank = seq_len(nrow(.))) %>% \n  # Création du graphique\n  pivot_longer(cols = -rank) %>% \n  ggplot() +\n    geom_line(aes(x = rank, y = value, color = name, lty = name)) +\n    scale_x_log10() +\n    labs(\n      x = \"Rang de l'espèce\", \n      y = \"Probabilité\", \n      color = \"Carré\",\n      lty = \"Carré\"\n    ) "}]
